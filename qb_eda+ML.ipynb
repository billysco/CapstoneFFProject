{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in datafrane\n",
    "df = pd.read_csv('qb_final1.csv')\n",
    "df = df.drop(columns=['Unnamed: 0', '3 Cone', 'Shuttle', 'Vertical Jump', 'Position', 'PK', 'PK1', 'Year_x', 'Year_y', 'Last_Year', 'year_drafted', 'AdjustedYds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round\n",
      "Pick\n",
      "Team\n",
      "Player\n",
      "Age\n",
      "School\n",
      "Weight\n",
      "40 Time\n",
      "Height (in)\n",
      "G\n",
      "Completions\n",
      "Attempts\n",
      "CompletionPCT\n",
      "PassYds\n",
      "YardsPerAttempt\n",
      "AdjustedYardsPerAttempt\n",
      "PassingTDs\n",
      "Int\n",
      "EfficiencyRtg\n",
      "RushAtt\n",
      "RushYds\n",
      "RushAvg\n",
      "RushTD\n",
      "YPG\n",
      "Conf\n",
      "response\n"
     ]
    }
   ],
   "source": [
    "# checking column list\n",
    "for x in df.columns:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Round                       0\n",
       "Pick                        0\n",
       "Team                        0\n",
       "Player                      0\n",
       "Age                        19\n",
       "School                      0\n",
       "Weight                     24\n",
       "40 Time                    49\n",
       "Height (in)                24\n",
       "G                           0\n",
       "Completions                 0\n",
       "Attempts                    0\n",
       "CompletionPCT               0\n",
       "PassYds                     0\n",
       "YardsPerAttempt             0\n",
       "AdjustedYardsPerAttempt     0\n",
       "PassingTDs                  0\n",
       "Int                         0\n",
       "EfficiencyRtg               0\n",
       "RushAtt                     0\n",
       "RushYds                     0\n",
       "RushAvg                     0\n",
       "RushTD                      0\n",
       "YPG                         0\n",
       "Conf                        0\n",
       "response                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing rows that are na in the most important columns, since these will not be accurate\n",
    "df = df[(df['response'].notna()) & (df['PassYds'].notna())]\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276, 26)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting missing values to median in less critical columns\n",
    "df = df.copy()\n",
    "# df.loc[df['RushAvg'].isna(), 'RushAvg'] = 0\n",
    "df.loc[df['Weight'].isna(), 'Weight'] = df['Weight'].median()\n",
    "df.loc[df['40 Time'].isna(), '40 Time'] = df['40 Time'].median()\n",
    "df.loc[df['Height (in)'].isna(), 'Height (in)'] = df['Height (in)'].median()\n",
    "df.loc[df['Age'].isna(), 'Age'] = df['Age'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257, 26)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing outliers\n",
    "df = df[(np.abs(stats.zscore(df['Attempts'])) < 3)]\n",
    "df = df[(np.abs(stats.zscore(df['RushYds'])) < 3)]\n",
    "df = df[(np.abs(stats.zscore(df['PassYds'])) < 3)]\n",
    "df = df[(np.abs(stats.zscore(df['RushAtt'])) < 3)]\n",
    "df = df[(np.abs(stats.zscore(df['YPG'])) < 3)]\n",
    "df = df[(np.abs(stats.zscore(df['RushAtt'])) < 3)]\n",
    "df = df[(np.abs(stats.zscore(df['RushTD'])) < 3)]\n",
    "df = df[(np.abs(stats.zscore(df['AdjustedYardsPerAttempt'])) < 3)]\n",
    "df = df[(np.abs(stats.zscore(df['YardsPerAttempt'])) < 3)]\n",
    "df = df[(np.abs(stats.zscore(df['Int'])) < 3)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperating features and response\n",
    "df = df.reset_index(drop=True)\n",
    "response = df['response']\n",
    "df_features = df.drop(columns = ['Player', 'response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperating data into numeric and categorical columns\n",
    "df_cat = df[['Team', 'School', 'Conf']].copy()\n",
    "df_num = df.drop(columns = ['Team', 'School', 'Conf', 'Player', 'response']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Round      Pick       Age    Weight   40 Time  \\\n",
      "Round                    1.000000  0.989506  0.323656 -0.272132  0.145343   \n",
      "Pick                     0.989506  1.000000  0.313706 -0.266744  0.140259   \n",
      "Age                      0.323656  0.313706  1.000000 -0.133735  0.186115   \n",
      "Weight                  -0.272132 -0.266744 -0.133735  1.000000  0.125295   \n",
      "40 Time                  0.145343  0.140259  0.186115  0.125295  1.000000   \n",
      "Height (in)             -0.189366 -0.192415 -0.081051  0.589464  0.267964   \n",
      "G                       -0.109194 -0.102921  0.015079  0.003678  0.010439   \n",
      "Completions             -0.136876 -0.134508  0.040266  0.016627  0.123838   \n",
      "Attempts                -0.118536 -0.116714  0.031538  0.035471  0.126876   \n",
      "CompletionPCT           -0.114721 -0.110114  0.036026 -0.028341  0.039639   \n",
      "PassYds                 -0.157387 -0.158274  0.028139  0.011681  0.100500   \n",
      "YardsPerAttempt         -0.153798 -0.165068 -0.032969 -0.060083 -0.143514   \n",
      "AdjustedYardsPerAttempt -0.204076 -0.209672 -0.067147 -0.034824 -0.147565   \n",
      "PassingTDs              -0.198767 -0.198324  0.003329 -0.010846  0.071909   \n",
      "Int                     -0.009614 -0.009032  0.090822  0.012854  0.151952   \n",
      "EfficiencyRtg           -0.137605 -0.134706  0.020759 -0.040708  0.011044   \n",
      "RushAtt                 -0.117357 -0.101320 -0.085075 -0.043815 -0.367210   \n",
      "RushYds                 -0.128061 -0.110891 -0.156385 -0.110752 -0.524444   \n",
      "RushAvg                 -0.153842 -0.139933 -0.185901 -0.096571 -0.530694   \n",
      "RushTD                  -0.160601 -0.140143 -0.155473 -0.027789 -0.397126   \n",
      "YPG                     -0.146532 -0.158614  0.005016  0.026537  0.201591   \n",
      "response                 0.641722  0.654464  0.306270 -0.162934  0.157705   \n",
      "\n",
      "                         Height (in)         G  Completions  Attempts  \\\n",
      "Round                      -0.189366 -0.109194    -0.136876 -0.118536   \n",
      "Pick                       -0.192415 -0.102921    -0.134508 -0.116714   \n",
      "Age                        -0.081051  0.015079     0.040266  0.031538   \n",
      "Weight                      0.589464  0.003678     0.016627  0.035471   \n",
      "40 Time                     0.267964  0.010439     0.123838  0.126876   \n",
      "Height (in)                 1.000000  0.000950     0.062540  0.082414   \n",
      "G                           0.000950  1.000000     0.852376  0.887471   \n",
      "Completions                 0.062540  0.852376     1.000000  0.983758   \n",
      "Attempts                    0.082414  0.887471     0.983758  1.000000   \n",
      "CompletionPCT              -0.022470  0.971987     0.883230  0.895543   \n",
      "PassYds                     0.031304  0.878615     0.971585  0.965297   \n",
      "YardsPerAttempt            -0.193507 -0.128693    -0.136644 -0.216772   \n",
      "AdjustedYardsPerAttempt    -0.152948 -0.104729    -0.057957 -0.151931   \n",
      "PassingTDs                 -0.029977  0.770282     0.879730  0.848943   \n",
      "Int                         0.037627  0.772851     0.755771  0.821496   \n",
      "EfficiencyRtg              -0.060806  0.959222     0.837736  0.848940   \n",
      "RushAtt                    -0.221423  0.585564     0.413426  0.432217   \n",
      "RushYds                    -0.303828  0.187628     0.017935  0.003363   \n",
      "RushAvg                    -0.299154  0.141254    -0.019650 -0.034708   \n",
      "RushTD                     -0.190399  0.369777     0.248487  0.249286   \n",
      "YPG                         0.075010 -0.013446     0.424498  0.354786   \n",
      "response                   -0.137885 -0.111794    -0.142023 -0.114297   \n",
      "\n",
      "                         CompletionPCT   PassYds  YardsPerAttempt  \\\n",
      "Round                        -0.114721 -0.157387        -0.153798   \n",
      "Pick                         -0.110114 -0.158274        -0.165068   \n",
      "Age                           0.036026  0.028139        -0.032969   \n",
      "Weight                       -0.028341  0.011681        -0.060083   \n",
      "40 Time                       0.039639  0.100500        -0.143514   \n",
      "Height (in)                  -0.022470  0.031304        -0.193507   \n",
      "G                             0.971987  0.878615        -0.128693   \n",
      "Completions                   0.883230  0.971585        -0.136644   \n",
      "Attempts                      0.895543  0.965297        -0.216772   \n",
      "CompletionPCT                 1.000000  0.894157        -0.104516   \n",
      "PassYds                       0.894157  1.000000         0.022984   \n",
      "YardsPerAttempt              -0.104516  0.022984         1.000000   \n",
      "AdjustedYardsPerAttempt      -0.076429  0.073947         0.943576   \n",
      "PassingTDs                    0.793892  0.924518         0.169640   \n",
      "Int                           0.767885  0.743047        -0.364898   \n",
      "EfficiencyRtg                 0.979527  0.891003         0.053148   \n",
      "RushAtt                       0.567914  0.434531        -0.033235   \n",
      "RushYds                       0.169510  0.042659         0.138777   \n",
      "RushAvg                       0.124012  0.001699         0.131895   \n",
      "RushTD                        0.345234  0.278661         0.081175   \n",
      "YPG                           0.066432  0.440045         0.301746   \n",
      "response                     -0.122977 -0.163174        -0.184540   \n",
      "\n",
      "                         AdjustedYardsPerAttempt  PassingTDs       Int  \\\n",
      "Round                                  -0.204076   -0.198767 -0.009614   \n",
      "Pick                                   -0.209672   -0.198324 -0.009032   \n",
      "Age                                    -0.067147    0.003329  0.090822   \n",
      "Weight                                 -0.034824   -0.010846  0.012854   \n",
      "40 Time                                -0.147565    0.071909  0.151952   \n",
      "Height (in)                            -0.152948   -0.029977  0.037627   \n",
      "G                                      -0.104729    0.770282  0.772851   \n",
      "Completions                            -0.057957    0.879730  0.755771   \n",
      "Attempts                               -0.151931    0.848943  0.821496   \n",
      "CompletionPCT                          -0.076429    0.793892  0.767885   \n",
      "PassYds                                 0.073947    0.924518  0.743047   \n",
      "YardsPerAttempt                         0.943576    0.169640 -0.364898   \n",
      "AdjustedYardsPerAttempt                 1.000000    0.268166 -0.439128   \n",
      "PassingTDs                              0.268166    1.000000  0.597577   \n",
      "Int                                    -0.439128    0.597577  1.000000   \n",
      "EfficiencyRtg                           0.074954    0.833749  0.706341   \n",
      "RushAtt                                -0.041503    0.363674  0.400777   \n",
      "RushYds                                 0.134994    0.070873 -0.022288   \n",
      "RushAvg                                 0.141191    0.036311 -0.090468   \n",
      "RushTD                                  0.083647    0.246988  0.193331   \n",
      "YPG                                     0.364754    0.477151  0.117713   \n",
      "response                               -0.210226   -0.195180 -0.028661   \n",
      "\n",
      "                         EfficiencyRtg   RushAtt   RushYds   RushAvg  \\\n",
      "Round                        -0.137605 -0.117357 -0.128061 -0.153842   \n",
      "Pick                         -0.134706 -0.101320 -0.110891 -0.139933   \n",
      "Age                           0.020759 -0.085075 -0.156385 -0.185901   \n",
      "Weight                       -0.040708 -0.043815 -0.110752 -0.096571   \n",
      "40 Time                       0.011044 -0.367210 -0.524444 -0.530694   \n",
      "Height (in)                  -0.060806 -0.221423 -0.303828 -0.299154   \n",
      "G                             0.959222  0.585564  0.187628  0.141254   \n",
      "Completions                   0.837736  0.413426  0.017935 -0.019650   \n",
      "Attempts                      0.848940  0.432217  0.003363 -0.034708   \n",
      "CompletionPCT                 0.979527  0.567914  0.169510  0.124012   \n",
      "PassYds                       0.891003  0.434531  0.042659  0.001699   \n",
      "YardsPerAttempt               0.053148 -0.033235  0.138777  0.131895   \n",
      "AdjustedYardsPerAttempt       0.074954 -0.041503  0.134994  0.141191   \n",
      "PassingTDs                    0.833749  0.363674  0.070873  0.036311   \n",
      "Int                           0.706341  0.400777 -0.022288 -0.090468   \n",
      "EfficiencyRtg                 1.000000  0.568344  0.197675  0.151726   \n",
      "RushAtt                       0.568344  1.000000  0.786371  0.678370   \n",
      "RushYds                       0.197675  0.786371  1.000000  0.905515   \n",
      "RushAvg                       0.151726  0.678370  0.905515  1.000000   \n",
      "RushTD                        0.360599  0.845439  0.839112  0.725583   \n",
      "YPG                           0.084916 -0.160227 -0.235616 -0.224691   \n",
      "response                     -0.144634 -0.123412 -0.149683 -0.181477   \n",
      "\n",
      "                           RushTD       YPG  response  \n",
      "Round                   -0.160601 -0.146532  0.641722  \n",
      "Pick                    -0.140143 -0.158614  0.654464  \n",
      "Age                     -0.155473  0.005016  0.306270  \n",
      "Weight                  -0.027789  0.026537 -0.162934  \n",
      "40 Time                 -0.397126  0.201591  0.157705  \n",
      "Height (in)             -0.190399  0.075010 -0.137885  \n",
      "G                        0.369777 -0.013446 -0.111794  \n",
      "Completions              0.248487  0.424498 -0.142023  \n",
      "Attempts                 0.249286  0.354786 -0.114297  \n",
      "CompletionPCT            0.345234  0.066432 -0.122977  \n",
      "PassYds                  0.278661  0.440045 -0.163174  \n",
      "YardsPerAttempt          0.081175  0.301746 -0.184540  \n",
      "AdjustedYardsPerAttempt  0.083647  0.364754 -0.210226  \n",
      "PassingTDs               0.246988  0.477151 -0.195180  \n",
      "Int                      0.193331  0.117713 -0.028661  \n",
      "EfficiencyRtg            0.360599  0.084916 -0.144634  \n",
      "RushAtt                  0.845439 -0.160227 -0.123412  \n",
      "RushYds                  0.839112 -0.235616 -0.149683  \n",
      "RushAvg                  0.725583 -0.224691 -0.181477  \n",
      "RushTD                   1.000000 -0.080724 -0.172096  \n",
      "YPG                     -0.080724  1.000000 -0.134556  \n",
      "response                -0.172096 -0.134556  1.000000  \n"
     ]
    }
   ],
   "source": [
    "# checking for high correlations with response variable\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 26.,  24.,  99., 108.]),\n",
       " array([1.  , 1.75, 2.5 , 3.25, 4.  ]),\n",
       " <BarContainer object of 4 artists>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAANt0lEQVR4nO3dfYxl9V3H8fenDEhbtAvsZF13sUNSosHGCk5wG5KGsJpQaFgSCdlG24VgNtFqqZi02/4h0b8gMX1S02YD6FaxhWyJrJRqyELT+EdXZwHLw7ayQShLFnb6ALTWWNd+/WNO62ScYe/cMzN37s/3K5nsfTj33u+Pw7737LlzZ1NVSJLa8rpRDyBJWnnGXZIaZNwlqUHGXZIaZNwlqUETox4AYOPGjTU1NTXqMSRprBw+fPibVTW52H3rIu5TU1PMzMyMegxJGitJnlvqPk/LSFKDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KD1sUnVCW1Y2rPF0Y9wlh59tarVuV5PXKXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAYZd0lqkHGXpAadMu5J7kxyIskT8247J8mDSZ7ufj27uz1JPpnkaJKvJrl4NYeXJC1ukCP3vwSuWHDbHuBgVV0AHOyuA7wTuKD72g18amXGlCQtxynjXlVfBr694OYdwL7u8j7gmnm3f6bmfAXYkGTzCs0qSRrQsOfcN1XV8e7yi8Cm7vIW4Pl52x3rbvs/kuxOMpNkZnZ2dsgxJEmL6f2GalUVUEM8bm9VTVfV9OTkZN8xJEnzDPuPdbyUZHNVHe9Ou5zobn8BOG/edlu726Sx5D88oXE17JH7AWBXd3kXcN+829/bfdfMNuCVeadvJElr5JRH7kk+C1wGbExyDLgFuBW4J8mNwHPAdd3mDwBXAkeB7wM3rMLMkqRTOGXcq+rdS9y1fZFtC3hf36EkSf34CVVJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJalCvuCf5/SRPJnkiyWeTnJnk/CSHkhxNcneSM1ZqWEnSYIaOe5ItwPuB6ap6K3AasBO4DfhYVb0F+A5w40oMKkkaXN/TMhPA65NMAG8AjgOXA/u7+/cB1/R8DUnSMg0d96p6AfgT4BvMRf0V4DDwclWd7DY7BmxZ7PFJdieZSTIzOzs77BiSpEX0OS1zNrADOB/4GeCNwBWDPr6q9lbVdFVNT05ODjuGJGkRfU7L/Crwb1U1W1X/BdwLXAps6E7TAGwFXug5oyRpmfrE/RvAtiRvSBJgO/AU8DBwbbfNLuC+fiNKkparzzn3Q8y9cfoI8Hj3XHuBDwE3JzkKnAvcsQJzSpKWYeLUmyytqm4Bbllw8zPAJX2eV5LUj59QlaQGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJalCvuCfZkGR/kq8lOZLk7UnOSfJgkqe7X89eqWElSYPpe+T+CeDvq+rngbcBR4A9wMGqugA42F2XJK2hoeOe5E3AO4A7AKrqB1X1MrAD2Ndttg+4pt+IkqTl6nPkfj4wC/xFkkeT3J7kjcCmqjrebfMisGmxByfZnWQmyczs7GyPMSRJC/WJ+wRwMfCpqroI+HcWnIKpqgJqsQdX1d6qmq6q6cnJyR5jSJIW6hP3Y8CxqjrUXd/PXOxfSrIZoPv1RL8RJUnLNXTcq+pF4PkkP9fdtB14CjgA7Opu2wXc12tCSdKyTfR8/O8BdyU5A3gGuIG5PzDuSXIj8BxwXc/XkCQtU6+4V9VjwPQid23v87ySpH78hKokNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNah33JOcluTRJPd3189PcijJ0SR3Jzmj/5iSpOVYiSP3m4Aj867fBnysqt4CfAe4cQVeQ5K0DL3inmQrcBVwe3c9wOXA/m6TfcA1fV5DkrR8fY/cPw58EPhhd/1c4OWqOtldPwZsWeyBSXYnmUkyMzs723MMSdJ8Q8c9ybuAE1V1eJjHV9XeqpququnJyclhx5AkLWKix2MvBa5OciVwJvBTwCeADUkmuqP3rcAL/ceUJC3H0EfuVfXhqtpaVVPATuChqvoN4GHg2m6zXcB9vaeUJC3Lanyf+4eAm5McZe4c/B2r8BqSpNfQ57TMj1XVl4AvdZefAS5ZieeVJA3HT6hKUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoMmRj1AX1N7vjDqEcbKs7deNeoRJK0Bj9wlqUHGXZIaZNwlqUFjf85dy+N7FNL/Dx65S1KDjLskNci4S1KDho57kvOSPJzkqSRPJrmpu/2cJA8mebr79eyVG1eSNIg+R+4ngT+oqguBbcD7klwI7AEOVtUFwMHuuiRpDQ0d96o6XlWPdJe/CxwBtgA7gH3dZvuAa3rOKElaphU5555kCrgIOARsqqrj3V0vApuWeMzuJDNJZmZnZ1diDElSp3fck5wFfB74QFW9Ov++qiqgFntcVe2tqumqmp6cnOw7hiRpnl5xT3I6c2G/q6ru7W5+Kcnm7v7NwIl+I0qSlqvPd8sEuAM4UlUfnXfXAWBXd3kXcN/w40mShtHnxw9cCrwHeDzJY91tHwFuBe5JciPwHHBdrwklScs2dNyr6h+BLHH39mGfV5LUn59QlaQGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJapBxl6QGGXdJatCqxD3JFUm+nuRokj2r8RqSpKWteNyTnAb8OfBO4ELg3UkuXOnXkSQtbTWO3C8BjlbVM1X1A+BzwI5VeB1J0hImVuE5twDPz7t+DPiVhRsl2Q3s7q5+L8nXh3y9jcA3h3zseuNa1p9W1gGuZV3Kbb3W8ual7liNuA+kqvYCe/s+T5KZqppegZFGzrWsP62sA1zLerVaa1mN0zIvAOfNu761u02StEZWI+7/DFyQ5PwkZwA7gQOr8DqSpCWs+GmZqjqZ5HeBfwBOA+6sqidX+nXm6X1qZx1xLetPK+sA17JercpaUlWr8bySpBHyE6qS1CDjLkkNGou4J7kzyYkkTyxxf5J8svtxB19NcvFazzioAdZyWZJXkjzWff3hWs84qCTnJXk4yVNJnkxy0yLbrPt9M+A6xmK/JDkzyT8l+ZduLX+0yDY/keTubp8cSjI1glFPacC1XJ9kdt5++a1RzDqIJKcleTTJ/Yvct/L7pKrW/RfwDuBi4Ikl7r8S+CIQYBtwaNQz91jLZcD9o55zwLVsBi7uLv8k8K/AheO2bwZcx1jsl+6/81nd5dOBQ8C2Bdv8DvDp7vJO4O5Rz91jLdcDfzbqWQdcz83A3yz2/9Fq7JOxOHKvqi8D336NTXYAn6k5XwE2JNm8NtMtzwBrGRtVdbyqHukufxc4wtwnlOdb9/tmwHWMhe6/8/e6q6d3Xwu/a2IHsK+7vB/YniRrNOLABlzLWEiyFbgKuH2JTVZ8n4xF3Aew2I88GMvfnJ23d38V/WKSXxj1MIPo/hp5EXNHV/ON1b55jXXAmOyX7q//jwEngAerasl9UlUngVeAc9d0yAENsBaAX+9O+e1Pct4i968HHwc+CPxwiftXfJ+0EveWPAK8uareBvwp8LejHefUkpwFfB74QFW9Oup5hnWKdYzNfqmq/66qX2Lu0+GXJHnriEca2gBr+Ttgqqp+EXiQ/z36XTeSvAs4UVWH1/J1W4l7Mz/yoKpe/dFfRavqAeD0JBtHPNaSkpzOXBDvqqp7F9lkLPbNqdYxbvsFoKpeBh4Grlhw14/3SZIJ4E3At9Z0uGVaai1V9a2q+s/u6u3AL6/xaIO4FLg6ybPM/ZTcy5P89YJtVnyftBL3A8B7u+/M2Aa8UlXHRz3UMJL89I/OtSW5hLl9tC5/43Vz3gEcqaqPLrHZut83g6xjXPZLkskkG7rLrwd+Dfjags0OALu6y9cCD1X3Tt56MshaFrx/czVz75esK1X14araWlVTzL1Z+lBV/eaCzVZ8n4zsp0IuR5LPMvfdChuTHANuYe7NFarq08ADzH1XxlHg+8ANo5n01AZYy7XAbyc5CfwHsHM9/sbrXAq8B3i8Oy8K8BHgZ2Gs9s0g6xiX/bIZ2Je5fzTndcA9VXV/kj8GZqrqAHN/kP1VkqPMvbm/c3TjvqZB1vL+JFcDJ5lby/Ujm3aZVnuf+OMHJKlBrZyWkSTNY9wlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIa9D821W8PQhkpFQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# checking distribution\n",
    "plt.hist(df['response'], bins=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2., 30.,  1., 55., 43., 16., 54., 27., 16., 13.]),\n",
       " array([ 5. ,  9.8, 14.6, 19.4, 24.2, 29. , 33.8, 38.6, 43.4, 48.2, 53. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['G'], bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([20., 30., 45., 38., 37., 39., 21., 16.,  6.,  5.]),\n",
       " array([ 116. ,  229.1,  342.2,  455.3,  568.4,  681.5,  794.6,  907.7,\n",
       "        1020.8, 1133.9, 1247. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this cell was run on all columns originally\n",
    "plt.hist(df['Completions'], bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating training and testing data for catboost model\n",
    "X_train_cb, X_test_cb, y_train_cb, y_test_cb = train_test_split(df_features, response, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.1863403\ttest: 1.2344260\tbest: 1.2344260 (0)\ttotal: 157ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.234426016\n",
      "bestIteration = 0\n",
      "\n",
      "0:\tloss: 1.2344260\tbest: 1.2344260 (0)\ttotal: 192ms\tremaining: 14.2s\n",
      "0:\tlearn: 1.0327952\ttest: 1.1465398\tbest: 1.1465398 (0)\ttotal: 609us\tremaining: 0us\n",
      "\n",
      "bestTest = 1.146539771\n",
      "bestIteration = 0\n",
      "\n",
      "1:\tloss: 1.1465398\tbest: 1.1465398 (1)\ttotal: 194ms\tremaining: 7.08s\n",
      "0:\tlearn: 1.0012913\ttest: 1.1653031\tbest: 1.1653031 (0)\ttotal: 547us\tremaining: 0us\n",
      "\n",
      "bestTest = 1.165303103\n",
      "bestIteration = 0\n",
      "\n",
      "2:\tloss: 1.1653031\tbest: 1.1465398 (1)\ttotal: 196ms\tremaining: 4.69s\n",
      "0:\tlearn: 1.1863403\ttest: 1.2344260\tbest: 1.2344260 (0)\ttotal: 628us\tremaining: 628us\n",
      "1:\tlearn: 1.1329447\ttest: 1.2030506\tbest: 1.2030506 (1)\ttotal: 1.16ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.203050623\n",
      "bestIteration = 1\n",
      "\n",
      "3:\tloss: 1.2030506\tbest: 1.1465398 (1)\ttotal: 198ms\tremaining: 3.52s\n",
      "0:\tlearn: 1.0327952\ttest: 1.1465398\tbest: 1.1465398 (0)\ttotal: 751us\tremaining: 751us\n",
      "1:\tlearn: 1.0019504\ttest: 1.1486132\tbest: 1.1465398 (0)\ttotal: 1.26ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.146539771\n",
      "bestIteration = 0\n",
      "\n",
      "4:\tloss: 1.1465398\tbest: 1.1465398 (1)\ttotal: 201ms\tremaining: 2.81s\n",
      "0:\tlearn: 1.0012913\ttest: 1.1653031\tbest: 1.1653031 (0)\ttotal: 586us\tremaining: 586us\n",
      "1:\tlearn: 0.9906123\ttest: 1.1782327\tbest: 1.1653031 (0)\ttotal: 1.19ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.165303103\n",
      "bestIteration = 0\n",
      "\n",
      "5:\tloss: 1.1653031\tbest: 1.1465398 (1)\ttotal: 204ms\tremaining: 2.34s\n",
      "0:\tlearn: 1.1863403\ttest: 1.2344260\tbest: 1.2344260 (0)\ttotal: 736us\tremaining: 1.47ms\n",
      "1:\tlearn: 1.1329447\ttest: 1.2030506\tbest: 1.2030506 (1)\ttotal: 1.32ms\tremaining: 661us\n",
      "2:\tlearn: 1.0682778\ttest: 1.1517719\tbest: 1.1517719 (2)\ttotal: 1.99ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.151771902\n",
      "bestIteration = 2\n",
      "\n",
      "6:\tloss: 1.1517719\tbest: 1.1465398 (1)\ttotal: 207ms\tremaining: 2.02s\n",
      "0:\tlearn: 1.0327952\ttest: 1.1465398\tbest: 1.1465398 (0)\ttotal: 797us\tremaining: 1.59ms\n",
      "1:\tlearn: 1.0019504\ttest: 1.1486132\tbest: 1.1465398 (0)\ttotal: 1.39ms\tremaining: 693us\n",
      "2:\tlearn: 0.9456400\ttest: 1.1072578\tbest: 1.1072578 (2)\ttotal: 1.89ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.107257793\n",
      "bestIteration = 2\n",
      "\n",
      "7:\tloss: 1.1072578\tbest: 1.1072578 (7)\ttotal: 211ms\tremaining: 1.77s\n",
      "0:\tlearn: 1.0012913\ttest: 1.1653031\tbest: 1.1653031 (0)\ttotal: 739us\tremaining: 1.48ms\n",
      "1:\tlearn: 0.9906123\ttest: 1.1782327\tbest: 1.1653031 (0)\ttotal: 1.25ms\tremaining: 624us\n",
      "2:\tlearn: 0.9335792\ttest: 1.1227601\tbest: 1.1227601 (2)\ttotal: 1.78ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.122760075\n",
      "bestIteration = 2\n",
      "\n",
      "8:\tloss: 1.1227601\tbest: 1.1072578 (7)\ttotal: 215ms\tremaining: 1.57s\n",
      "0:\tlearn: 1.1863403\ttest: 1.2344260\tbest: 1.2344260 (0)\ttotal: 1.08ms\tremaining: 3.23ms\n",
      "1:\tlearn: 1.1329447\ttest: 1.2030506\tbest: 1.2030506 (1)\ttotal: 1.63ms\tremaining: 1.63ms\n",
      "2:\tlearn: 1.0682778\ttest: 1.1517719\tbest: 1.1517719 (2)\ttotal: 2.16ms\tremaining: 718us\n",
      "3:\tlearn: 1.0513237\ttest: 1.1498658\tbest: 1.1498658 (3)\ttotal: 8.58ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.149865765\n",
      "bestIteration = 3\n",
      "\n",
      "9:\tloss: 1.1498658\tbest: 1.1072578 (7)\ttotal: 225ms\tremaining: 1.46s\n",
      "0:\tlearn: 1.0327952\ttest: 1.1465398\tbest: 1.1465398 (0)\ttotal: 868us\tremaining: 2.6ms\n",
      "1:\tlearn: 1.0019504\ttest: 1.1486132\tbest: 1.1465398 (0)\ttotal: 1.78ms\tremaining: 1.78ms\n",
      "2:\tlearn: 0.9456400\ttest: 1.1072578\tbest: 1.1072578 (2)\ttotal: 2.43ms\tremaining: 809us\n",
      "3:\tlearn: 0.9125002\ttest: 1.0921177\tbest: 1.0921177 (3)\ttotal: 8.61ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.092117674\n",
      "bestIteration = 3\n",
      "\n",
      "10:\tloss: 1.0921177\tbest: 1.0921177 (10)\ttotal: 235ms\tremaining: 1.37s\n",
      "0:\tlearn: 1.0012913\ttest: 1.1653031\tbest: 1.1653031 (0)\ttotal: 689us\tremaining: 2.07ms\n",
      "1:\tlearn: 0.9906123\ttest: 1.1782327\tbest: 1.1653031 (0)\ttotal: 1.16ms\tremaining: 1.16ms\n",
      "2:\tlearn: 0.9335792\ttest: 1.1227601\tbest: 1.1227601 (2)\ttotal: 1.66ms\tremaining: 552us\n",
      "3:\tlearn: 0.8936483\ttest: 1.1016804\tbest: 1.1016804 (3)\ttotal: 7.47ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.101680447\n",
      "bestIteration = 3\n",
      "\n",
      "11:\tloss: 1.1016804\tbest: 1.0921177 (10)\ttotal: 244ms\tremaining: 1.28s\n",
      "0:\tlearn: 1.1863403\ttest: 1.2344260\tbest: 1.2344260 (0)\ttotal: 677us\tremaining: 2.71ms\n",
      "1:\tlearn: 1.1329447\ttest: 1.2030506\tbest: 1.2030506 (1)\ttotal: 1.23ms\tremaining: 1.85ms\n",
      "2:\tlearn: 1.0682778\ttest: 1.1517719\tbest: 1.1517719 (2)\ttotal: 1.72ms\tremaining: 1.15ms\n",
      "3:\tlearn: 1.0513237\ttest: 1.1498658\tbest: 1.1498658 (3)\ttotal: 7.32ms\tremaining: 1.83ms\n",
      "4:\tlearn: 1.0272283\ttest: 1.1423588\tbest: 1.1423588 (4)\ttotal: 12.7ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.142358777\n",
      "bestIteration = 4\n",
      "\n",
      "12:\tloss: 1.1423588\tbest: 1.0921177 (10)\ttotal: 259ms\tremaining: 1.24s\n",
      "0:\tlearn: 1.0327952\ttest: 1.1465398\tbest: 1.1465398 (0)\ttotal: 549us\tremaining: 2.2ms\n",
      "1:\tlearn: 1.0019504\ttest: 1.1486132\tbest: 1.1465398 (0)\ttotal: 1.04ms\tremaining: 1.55ms\n",
      "2:\tlearn: 0.9456400\ttest: 1.1072578\tbest: 1.1072578 (2)\ttotal: 1.68ms\tremaining: 1.12ms\n",
      "3:\tlearn: 0.9125002\ttest: 1.0921177\tbest: 1.0921177 (3)\ttotal: 7.22ms\tremaining: 1.8ms\n",
      "4:\tlearn: 0.9039224\ttest: 1.0953910\tbest: 1.0921177 (3)\ttotal: 12.9ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.092117674\n",
      "bestIteration = 3\n",
      "\n",
      "13:\tloss: 1.0921177\tbest: 1.0921177 (10)\ttotal: 274ms\tremaining: 1.19s\n",
      "0:\tlearn: 1.0012913\ttest: 1.1653031\tbest: 1.1653031 (0)\ttotal: 757us\tremaining: 3.03ms\n",
      "1:\tlearn: 0.9906123\ttest: 1.1782327\tbest: 1.1653031 (0)\ttotal: 1.25ms\tremaining: 1.87ms\n",
      "2:\tlearn: 0.9335792\ttest: 1.1227601\tbest: 1.1227601 (2)\ttotal: 1.77ms\tremaining: 1.18ms\n",
      "3:\tlearn: 0.8936483\ttest: 1.1016804\tbest: 1.1016804 (3)\ttotal: 7.02ms\tremaining: 1.75ms\n",
      "4:\tlearn: 0.8855505\ttest: 1.1088725\tbest: 1.1016804 (3)\ttotal: 12.1ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.101680447\n",
      "bestIteration = 3\n",
      "\n",
      "14:\tloss: 1.1016804\tbest: 1.0921177 (10)\ttotal: 288ms\tremaining: 1.15s\n",
      "0:\tlearn: 1.2034023\ttest: 1.2462615\tbest: 1.2462615 (0)\ttotal: 5.61ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.24626147\n",
      "bestIteration = 0\n",
      "\n",
      "15:\tloss: 1.2462615\tbest: 1.0921177 (10)\ttotal: 295ms\tremaining: 1.09s\n",
      "0:\tlearn: 1.0494354\ttest: 1.1475975\tbest: 1.1475975 (0)\ttotal: 5.67ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.147597513\n",
      "bestIteration = 0\n",
      "\n",
      "16:\tloss: 1.1475975\tbest: 1.0921177 (10)\ttotal: 302ms\tremaining: 1.03s\n",
      "0:\tlearn: 1.0024829\ttest: 1.1407134\tbest: 1.1407134 (0)\ttotal: 5.56ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.140713362\n",
      "bestIteration = 0\n",
      "\n",
      "17:\tloss: 1.1407134\tbest: 1.0921177 (10)\ttotal: 309ms\tremaining: 979ms\n",
      "0:\tlearn: 1.2034023\ttest: 1.2462615\tbest: 1.2462615 (0)\ttotal: 5.6ms\tremaining: 5.6ms\n",
      "1:\tlearn: 1.0995994\ttest: 1.1807017\tbest: 1.1807017 (1)\ttotal: 15.5ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.180701723\n",
      "bestIteration = 1\n",
      "\n",
      "18:\tloss: 1.1807017\tbest: 1.0921177 (10)\ttotal: 326ms\tremaining: 962ms\n",
      "0:\tlearn: 1.0494354\ttest: 1.1475975\tbest: 1.1475975 (0)\ttotal: 5.7ms\tremaining: 5.7ms\n",
      "1:\tlearn: 0.9614018\ttest: 1.1223659\tbest: 1.1223659 (1)\ttotal: 15.3ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.122365852\n",
      "bestIteration = 1\n",
      "\n",
      "19:\tloss: 1.1223659\tbest: 1.0921177 (10)\ttotal: 343ms\tremaining: 944ms\n",
      "0:\tlearn: 1.0024829\ttest: 1.1407134\tbest: 1.1407134 (0)\ttotal: 5.63ms\tremaining: 5.63ms\n",
      "1:\tlearn: 0.8975134\ttest: 1.0863955\tbest: 1.0863955 (1)\ttotal: 14.8ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.086395499\n",
      "bestIteration = 1\n",
      "\n",
      "20:\tloss: 1.0863955\tbest: 1.0863955 (20)\ttotal: 360ms\tremaining: 926ms\n",
      "0:\tlearn: 1.2034023\ttest: 1.2462615\tbest: 1.2462615 (0)\ttotal: 5.37ms\tremaining: 10.7ms\n",
      "1:\tlearn: 1.0995994\ttest: 1.1807017\tbest: 1.1807017 (1)\ttotal: 15.4ms\tremaining: 7.68ms\n",
      "2:\tlearn: 1.0505603\ttest: 1.1530505\tbest: 1.1530505 (2)\ttotal: 26.2ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.15305053\n",
      "bestIteration = 2\n",
      "\n",
      "21:\tloss: 1.1530505\tbest: 1.0863955 (20)\ttotal: 389ms\tremaining: 936ms\n",
      "0:\tlearn: 1.0494354\ttest: 1.1475975\tbest: 1.1475975 (0)\ttotal: 16.4ms\tremaining: 32.8ms\n",
      "1:\tlearn: 0.9614018\ttest: 1.1223659\tbest: 1.1223659 (1)\ttotal: 39.6ms\tremaining: 19.8ms\n",
      "2:\tlearn: 0.9238674\ttest: 1.1525014\tbest: 1.1223659 (1)\ttotal: 49.2ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.122365852\n",
      "bestIteration = 1\n",
      "\n",
      "22:\tloss: 1.1223659\tbest: 1.0863955 (20)\ttotal: 440ms\tremaining: 995ms\n",
      "0:\tlearn: 1.0024829\ttest: 1.1407134\tbest: 1.1407134 (0)\ttotal: 5.77ms\tremaining: 11.5ms\n",
      "1:\tlearn: 0.8975134\ttest: 1.0863955\tbest: 1.0863955 (1)\ttotal: 15.9ms\tremaining: 7.94ms\n",
      "2:\tlearn: 0.8918511\ttest: 1.1093691\tbest: 1.0863955 (1)\ttotal: 27.2ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.086395499\n",
      "bestIteration = 1\n",
      "\n",
      "23:\tloss: 1.0863955\tbest: 1.0863955 (20)\ttotal: 469ms\tremaining: 997ms\n",
      "0:\tlearn: 1.2034023\ttest: 1.2462615\tbest: 1.2462615 (0)\ttotal: 5.84ms\tremaining: 17.5ms\n",
      "1:\tlearn: 1.0995994\ttest: 1.1807017\tbest: 1.1807017 (1)\ttotal: 15.3ms\tremaining: 15.3ms\n",
      "2:\tlearn: 1.0505603\ttest: 1.1530505\tbest: 1.1530505 (2)\ttotal: 25.8ms\tremaining: 8.58ms\n",
      "3:\tlearn: 1.0205949\ttest: 1.1508423\tbest: 1.1508423 (3)\ttotal: 35.5ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.150842271\n",
      "bestIteration = 3\n",
      "\n",
      "24:\tloss: 1.1508423\tbest: 1.0863955 (20)\ttotal: 507ms\tremaining: 1.01s\n",
      "0:\tlearn: 1.0494354\ttest: 1.1475975\tbest: 1.1475975 (0)\ttotal: 5.29ms\tremaining: 15.9ms\n",
      "1:\tlearn: 0.9614018\ttest: 1.1223659\tbest: 1.1223659 (1)\ttotal: 14.7ms\tremaining: 14.7ms\n",
      "2:\tlearn: 0.9238674\ttest: 1.1525014\tbest: 1.1223659 (1)\ttotal: 24ms\tremaining: 7.99ms\n",
      "3:\tlearn: 0.9003935\ttest: 1.1171730\tbest: 1.1171730 (3)\ttotal: 33.8ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.117172983\n",
      "bestIteration = 3\n",
      "\n",
      "25:\tloss: 1.1171730\tbest: 1.0863955 (20)\ttotal: 543ms\tremaining: 1.02s\n",
      "0:\tlearn: 1.0024829\ttest: 1.1407134\tbest: 1.1407134 (0)\ttotal: 5.38ms\tremaining: 16.2ms\n",
      "1:\tlearn: 0.8975134\ttest: 1.0863955\tbest: 1.0863955 (1)\ttotal: 14.9ms\tremaining: 14.9ms\n",
      "2:\tlearn: 0.8918511\ttest: 1.1093691\tbest: 1.0863955 (1)\ttotal: 26.3ms\tremaining: 8.76ms\n",
      "3:\tlearn: 0.8655256\ttest: 1.0542441\tbest: 1.0542441 (3)\ttotal: 37.1ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.054244122\n",
      "bestIteration = 3\n",
      "\n",
      "26:\tloss: 1.0542441\tbest: 1.0542441 (26)\ttotal: 583ms\tremaining: 1.04s\n",
      "0:\tlearn: 1.2034023\ttest: 1.2462615\tbest: 1.2462615 (0)\ttotal: 6.55ms\tremaining: 26.2ms\n",
      "1:\tlearn: 1.0995994\ttest: 1.1807017\tbest: 1.1807017 (1)\ttotal: 16.7ms\tremaining: 25.1ms\n",
      "2:\tlearn: 1.0505603\ttest: 1.1530505\tbest: 1.1530505 (2)\ttotal: 26.2ms\tremaining: 17.5ms\n",
      "3:\tlearn: 1.0205949\ttest: 1.1508423\tbest: 1.1508423 (3)\ttotal: 36.4ms\tremaining: 9.09ms\n",
      "4:\tlearn: 1.0033779\ttest: 1.1485774\tbest: 1.1485774 (4)\ttotal: 47ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.148577375\n",
      "bestIteration = 4\n",
      "\n",
      "27:\tloss: 1.1485774\tbest: 1.0542441 (26)\ttotal: 633ms\tremaining: 1.06s\n",
      "0:\tlearn: 1.0494354\ttest: 1.1475975\tbest: 1.1475975 (0)\ttotal: 5.27ms\tremaining: 21.1ms\n",
      "1:\tlearn: 0.9614018\ttest: 1.1223659\tbest: 1.1223659 (1)\ttotal: 14.9ms\tremaining: 22.3ms\n",
      "2:\tlearn: 0.9238674\ttest: 1.1525014\tbest: 1.1223659 (1)\ttotal: 24.5ms\tremaining: 16.3ms\n",
      "3:\tlearn: 0.9003935\ttest: 1.1171730\tbest: 1.1171730 (3)\ttotal: 33.7ms\tremaining: 8.43ms\n",
      "4:\tlearn: 0.8874025\ttest: 1.1182596\tbest: 1.1171730 (3)\ttotal: 43.7ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.117172983\n",
      "bestIteration = 3\n",
      "\n",
      "28:\tloss: 1.1171730\tbest: 1.0542441 (26)\ttotal: 679ms\tremaining: 1.08s\n",
      "0:\tlearn: 1.0024829\ttest: 1.1407134\tbest: 1.1407134 (0)\ttotal: 6.33ms\tremaining: 25.3ms\n",
      "1:\tlearn: 0.8975134\ttest: 1.0863955\tbest: 1.0863955 (1)\ttotal: 16.8ms\tremaining: 25.2ms\n",
      "2:\tlearn: 0.8918511\ttest: 1.1093691\tbest: 1.0863955 (1)\ttotal: 26.8ms\tremaining: 17.9ms\n",
      "3:\tlearn: 0.8655256\ttest: 1.0542441\tbest: 1.0542441 (3)\ttotal: 36.2ms\tremaining: 9.06ms\n",
      "4:\tlearn: 0.8457506\ttest: 1.0375804\tbest: 1.0375804 (4)\ttotal: 46.1ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.037580429\n",
      "bestIteration = 4\n",
      "\n",
      "29:\tloss: 1.0375804\tbest: 1.0375804 (29)\ttotal: 727ms\tremaining: 1.09s\n",
      "0:\tlearn: 1.2204452\ttest: 1.2723687\tbest: 1.2723687 (0)\ttotal: 15.3ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.272368748\n",
      "bestIteration = 0\n",
      "\n",
      "30:\tloss: 1.2723687\tbest: 1.0375804 (29)\ttotal: 744ms\tremaining: 1.06s\n",
      "0:\tlearn: 1.0633080\ttest: 1.1806378\tbest: 1.1806378 (0)\ttotal: 17.3ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.180637814\n",
      "bestIteration = 0\n",
      "\n",
      "31:\tloss: 1.1806378\tbest: 1.0375804 (29)\ttotal: 764ms\tremaining: 1.03s\n",
      "0:\tlearn: 0.9950699\ttest: 1.1587841\tbest: 1.1587841 (0)\ttotal: 16.7ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.158784143\n",
      "bestIteration = 0\n",
      "\n",
      "32:\tloss: 1.1587841\tbest: 1.0375804 (29)\ttotal: 783ms\tremaining: 996ms\n",
      "0:\tlearn: 1.2204452\ttest: 1.2723687\tbest: 1.2723687 (0)\ttotal: 15.6ms\tremaining: 15.6ms\n",
      "1:\tlearn: 1.1101703\ttest: 1.1880137\tbest: 1.1880137 (1)\ttotal: 34.9ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.188013688\n",
      "bestIteration = 1\n",
      "\n",
      "33:\tloss: 1.1880137\tbest: 1.0375804 (29)\ttotal: 820ms\tremaining: 989ms\n",
      "0:\tlearn: 1.0633080\ttest: 1.1806378\tbest: 1.1806378 (0)\ttotal: 15.7ms\tremaining: 15.7ms\n",
      "1:\tlearn: 0.9157760\ttest: 1.0762167\tbest: 1.0762167 (1)\ttotal: 35.6ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.076216673\n",
      "bestIteration = 1\n",
      "\n",
      "34:\tloss: 1.0762167\tbest: 1.0375804 (29)\ttotal: 858ms\tremaining: 980ms\n",
      "0:\tlearn: 0.9950699\ttest: 1.1587841\tbest: 1.1587841 (0)\ttotal: 15.4ms\tremaining: 15.4ms\n",
      "1:\tlearn: 0.8478159\ttest: 1.0782309\tbest: 1.0782309 (1)\ttotal: 36.2ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.078230924\n",
      "bestIteration = 1\n",
      "\n",
      "35:\tloss: 1.0782309\tbest: 1.0375804 (29)\ttotal: 897ms\tremaining: 971ms\n",
      "0:\tlearn: 1.2204452\ttest: 1.2723687\tbest: 1.2723687 (0)\ttotal: 15.9ms\tremaining: 31.9ms\n",
      "1:\tlearn: 1.1101703\ttest: 1.1880137\tbest: 1.1880137 (1)\ttotal: 36.4ms\tremaining: 18.2ms\n",
      "2:\tlearn: 1.0334307\ttest: 1.1356966\tbest: 1.1356966 (2)\ttotal: 59.5ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.135696625\n",
      "bestIteration = 2\n",
      "\n",
      "36:\tloss: 1.1356966\tbest: 1.0375804 (29)\ttotal: 959ms\tremaining: 985ms\n",
      "0:\tlearn: 1.0633080\ttest: 1.1806378\tbest: 1.1806378 (0)\ttotal: 15.9ms\tremaining: 31.8ms\n",
      "1:\tlearn: 0.9157760\ttest: 1.0762167\tbest: 1.0762167 (1)\ttotal: 36.5ms\tremaining: 18.2ms\n",
      "2:\tlearn: 0.8511758\ttest: 1.0578456\tbest: 1.0578456 (2)\ttotal: 56.2ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.057845591\n",
      "bestIteration = 2\n",
      "\n",
      "37:\tloss: 1.0578456\tbest: 1.0375804 (29)\ttotal: 1.02s\tremaining: 991ms\n",
      "0:\tlearn: 0.9950699\ttest: 1.1587841\tbest: 1.1587841 (0)\ttotal: 14.9ms\tremaining: 29.8ms\n",
      "1:\tlearn: 0.8478159\ttest: 1.0782309\tbest: 1.0782309 (1)\ttotal: 34.5ms\tremaining: 17.3ms\n",
      "2:\tlearn: 0.7700830\ttest: 1.0138162\tbest: 1.0138162 (2)\ttotal: 53.8ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.013816181\n",
      "bestIteration = 2\n",
      "\n",
      "38:\tloss: 1.0138162\tbest: 1.0138162 (38)\ttotal: 1.07s\tremaining: 991ms\n",
      "0:\tlearn: 1.2204452\ttest: 1.2723687\tbest: 1.2723687 (0)\ttotal: 14.9ms\tremaining: 44.8ms\n",
      "1:\tlearn: 1.1101703\ttest: 1.1880137\tbest: 1.1880137 (1)\ttotal: 34.1ms\tremaining: 34.1ms\n",
      "2:\tlearn: 1.0334307\ttest: 1.1356966\tbest: 1.1356966 (2)\ttotal: 53.4ms\tremaining: 17.8ms\n",
      "3:\tlearn: 0.9759823\ttest: 1.1145543\tbest: 1.1145543 (3)\ttotal: 76.1ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.114554317\n",
      "bestIteration = 3\n",
      "\n",
      "39:\tloss: 1.1145543\tbest: 1.0138162 (38)\ttotal: 1.15s\tremaining: 1.01s\n",
      "0:\tlearn: 1.0633080\ttest: 1.1806378\tbest: 1.1806378 (0)\ttotal: 16.4ms\tremaining: 49.3ms\n",
      "1:\tlearn: 0.9157760\ttest: 1.0762167\tbest: 1.0762167 (1)\ttotal: 36.8ms\tremaining: 36.8ms\n",
      "2:\tlearn: 0.8511758\ttest: 1.0578456\tbest: 1.0578456 (2)\ttotal: 56.3ms\tremaining: 18.8ms\n",
      "3:\tlearn: 0.8223932\ttest: 1.0566150\tbest: 1.0566150 (3)\ttotal: 86.5ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.056615043\n",
      "bestIteration = 3\n",
      "\n",
      "40:\tloss: 1.0566150\tbest: 1.0138162 (38)\ttotal: 1.24s\tremaining: 1.03s\n",
      "0:\tlearn: 0.9950699\ttest: 1.1587841\tbest: 1.1587841 (0)\ttotal: 15.9ms\tremaining: 47.8ms\n",
      "1:\tlearn: 0.8478159\ttest: 1.0782309\tbest: 1.0782309 (1)\ttotal: 36ms\tremaining: 36ms\n",
      "2:\tlearn: 0.7700830\ttest: 1.0138162\tbest: 1.0138162 (2)\ttotal: 55.5ms\tremaining: 18.5ms\n",
      "3:\tlearn: 0.7414148\ttest: 1.0199112\tbest: 1.0138162 (2)\ttotal: 74.9ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.013816181\n",
      "bestIteration = 2\n",
      "\n",
      "41:\tloss: 1.0138162\tbest: 1.0138162 (38)\ttotal: 1.32s\tremaining: 1.04s\n",
      "0:\tlearn: 1.2204452\ttest: 1.2723687\tbest: 1.2723687 (0)\ttotal: 17.9ms\tremaining: 71.7ms\n",
      "1:\tlearn: 1.1101703\ttest: 1.1880137\tbest: 1.1880137 (1)\ttotal: 39.2ms\tremaining: 58.7ms\n",
      "2:\tlearn: 1.0334307\ttest: 1.1356966\tbest: 1.1356966 (2)\ttotal: 58.8ms\tremaining: 39.2ms\n",
      "3:\tlearn: 0.9759823\ttest: 1.1145543\tbest: 1.1145543 (3)\ttotal: 78ms\tremaining: 19.5ms\n",
      "4:\tlearn: 0.9340476\ttest: 1.1022222\tbest: 1.1022222 (4)\ttotal: 97.5ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.102222204\n",
      "bestIteration = 4\n",
      "\n",
      "42:\tloss: 1.1022222\tbest: 1.0138162 (38)\ttotal: 1.42s\tremaining: 1.06s\n",
      "0:\tlearn: 1.0633080\ttest: 1.1806378\tbest: 1.1806378 (0)\ttotal: 15ms\tremaining: 60ms\n",
      "1:\tlearn: 0.9157760\ttest: 1.0762167\tbest: 1.0762167 (1)\ttotal: 34.3ms\tremaining: 51.4ms\n",
      "2:\tlearn: 0.8511758\ttest: 1.0578456\tbest: 1.0578456 (2)\ttotal: 53.7ms\tremaining: 35.8ms\n",
      "3:\tlearn: 0.8223932\ttest: 1.0566150\tbest: 1.0566150 (3)\ttotal: 75.6ms\tremaining: 18.9ms\n",
      "4:\tlearn: 0.7668899\ttest: 1.0338430\tbest: 1.0338430 (4)\ttotal: 96.5ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.033843038\n",
      "bestIteration = 4\n",
      "\n",
      "43:\tloss: 1.0338430\tbest: 1.0138162 (38)\ttotal: 1.52s\tremaining: 1.07s\n",
      "0:\tlearn: 0.9950699\ttest: 1.1587841\tbest: 1.1587841 (0)\ttotal: 17.9ms\tremaining: 71.4ms\n",
      "1:\tlearn: 0.8478159\ttest: 1.0782309\tbest: 1.0782309 (1)\ttotal: 56.2ms\tremaining: 84.3ms\n",
      "2:\tlearn: 0.7700830\ttest: 1.0138162\tbest: 1.0138162 (2)\ttotal: 122ms\tremaining: 81.1ms\n",
      "3:\tlearn: 0.7414148\ttest: 1.0199112\tbest: 1.0138162 (2)\ttotal: 143ms\tremaining: 35.7ms\n",
      "4:\tlearn: 0.7091356\ttest: 0.9812275\tbest: 0.9812275 (4)\ttotal: 166ms\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9812274971\n",
      "bestIteration = 4\n",
      "\n",
      "44:\tloss: 0.9812275\tbest: 0.9812275 (44)\ttotal: 1.69s\tremaining: 1.13s\n",
      "0:\tlearn: 1.2588638\ttest: 1.3260773\tbest: 1.3260773 (0)\ttotal: 33.8ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.326077319\n",
      "bestIteration = 0\n",
      "\n",
      "45:\tloss: 1.3260773\tbest: 0.9812275 (44)\ttotal: 1.73s\tremaining: 1.09s\n",
      "0:\tlearn: 1.1179606\ttest: 1.2749840\tbest: 1.2749840 (0)\ttotal: 34.3ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.274984001\n",
      "bestIteration = 0\n",
      "\n",
      "46:\tloss: 1.2749840\tbest: 0.9812275 (44)\ttotal: 1.76s\tremaining: 1.05s\n",
      "0:\tlearn: 1.0351628\ttest: 1.2599759\tbest: 1.2599759 (0)\ttotal: 28.8ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.259975948\n",
      "bestIteration = 0\n",
      "\n",
      "47:\tloss: 1.2599759\tbest: 0.9812275 (44)\ttotal: 1.8s\tremaining: 1.01s\n",
      "0:\tlearn: 1.2588638\ttest: 1.3260773\tbest: 1.3260773 (0)\ttotal: 28.3ms\tremaining: 28.3ms\n",
      "1:\tlearn: 1.1497082\ttest: 1.2883887\tbest: 1.2883887 (1)\ttotal: 62.1ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.288388661\n",
      "bestIteration = 1\n",
      "\n",
      "48:\tloss: 1.2883887\tbest: 0.9812275 (44)\ttotal: 1.86s\tremaining: 988ms\n",
      "0:\tlearn: 1.1179606\ttest: 1.2749840\tbest: 1.2749840 (0)\ttotal: 29.4ms\tremaining: 29.4ms\n",
      "1:\tlearn: 1.0040559\ttest: 1.2305265\tbest: 1.2305265 (1)\ttotal: 64.9ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.230526504\n",
      "bestIteration = 1\n",
      "\n",
      "49:\tloss: 1.2305265\tbest: 0.9812275 (44)\ttotal: 1.93s\tremaining: 965ms\n",
      "0:\tlearn: 1.0351628\ttest: 1.2599759\tbest: 1.2599759 (0)\ttotal: 32.4ms\tremaining: 32.4ms\n",
      "1:\tlearn: 0.9114341\ttest: 1.2243212\tbest: 1.2243212 (1)\ttotal: 67.6ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.224321211\n",
      "bestIteration = 1\n",
      "\n",
      "50:\tloss: 1.2243212\tbest: 0.9812275 (44)\ttotal: 2s\tremaining: 942ms\n",
      "0:\tlearn: 1.2588638\ttest: 1.3260773\tbest: 1.3260773 (0)\ttotal: 29.6ms\tremaining: 59.1ms\n",
      "1:\tlearn: 1.1497082\ttest: 1.2883887\tbest: 1.2883887 (1)\ttotal: 64.7ms\tremaining: 32.4ms\n",
      "2:\tlearn: 1.0782001\ttest: 1.2388294\tbest: 1.2388294 (2)\ttotal: 76.9ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.238829413\n",
      "bestIteration = 2\n",
      "\n",
      "51:\tloss: 1.2388294\tbest: 0.9812275 (44)\ttotal: 2.08s\tremaining: 920ms\n",
      "0:\tlearn: 1.1179606\ttest: 1.2749840\tbest: 1.2749840 (0)\ttotal: 28.7ms\tremaining: 57.4ms\n",
      "1:\tlearn: 1.0040559\ttest: 1.2305265\tbest: 1.2305265 (1)\ttotal: 64ms\tremaining: 32ms\n",
      "2:\tlearn: 0.8807103\ttest: 1.1185304\tbest: 1.1185304 (2)\ttotal: 94.7ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.118530354\n",
      "bestIteration = 2\n",
      "\n",
      "52:\tloss: 1.1185304\tbest: 0.9812275 (44)\ttotal: 2.18s\tremaining: 904ms\n",
      "0:\tlearn: 1.0351628\ttest: 1.2599759\tbest: 1.2599759 (0)\ttotal: 29.1ms\tremaining: 58.1ms\n",
      "1:\tlearn: 0.9114341\ttest: 1.2243212\tbest: 1.2243212 (1)\ttotal: 62.6ms\tremaining: 31.3ms\n",
      "2:\tlearn: 0.8002168\ttest: 1.1609810\tbest: 1.1609810 (2)\ttotal: 89.2ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.160981018\n",
      "bestIteration = 2\n",
      "\n",
      "53:\tloss: 1.1609810\tbest: 0.9812275 (44)\ttotal: 2.27s\tremaining: 883ms\n",
      "0:\tlearn: 1.2588638\ttest: 1.3260773\tbest: 1.3260773 (0)\ttotal: 27.9ms\tremaining: 83.8ms\n",
      "1:\tlearn: 1.1497082\ttest: 1.2883887\tbest: 1.2883887 (1)\ttotal: 61.2ms\tremaining: 61.2ms\n",
      "2:\tlearn: 1.0782001\ttest: 1.2388294\tbest: 1.2388294 (2)\ttotal: 73.3ms\tremaining: 24.4ms\n",
      "3:\tlearn: 1.0039046\ttest: 1.2324835\tbest: 1.2324835 (3)\ttotal: 108ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.232483508\n",
      "bestIteration = 3\n",
      "\n",
      "54:\tloss: 1.2324835\tbest: 0.9812275 (44)\ttotal: 2.38s\tremaining: 867ms\n",
      "0:\tlearn: 1.1179606\ttest: 1.2749840\tbest: 1.2749840 (0)\ttotal: 28.4ms\tremaining: 85.1ms\n",
      "1:\tlearn: 1.0040559\ttest: 1.2305265\tbest: 1.2305265 (1)\ttotal: 61.8ms\tremaining: 61.8ms\n",
      "2:\tlearn: 0.8807103\ttest: 1.1185304\tbest: 1.1185304 (2)\ttotal: 89.9ms\tremaining: 30ms\n",
      "3:\tlearn: 0.8120330\ttest: 1.1155942\tbest: 1.1155942 (3)\ttotal: 124ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.115594185\n",
      "bestIteration = 3\n",
      "\n",
      "55:\tloss: 1.1155942\tbest: 0.9812275 (44)\ttotal: 2.51s\tremaining: 852ms\n",
      "0:\tlearn: 1.0351628\ttest: 1.2599759\tbest: 1.2599759 (0)\ttotal: 29.6ms\tremaining: 88.8ms\n",
      "1:\tlearn: 0.9114341\ttest: 1.2243212\tbest: 1.2243212 (1)\ttotal: 69.3ms\tremaining: 69.3ms\n",
      "2:\tlearn: 0.8002168\ttest: 1.1609810\tbest: 1.1609810 (2)\ttotal: 99.5ms\tremaining: 33.2ms\n",
      "3:\tlearn: 0.7010779\ttest: 1.1751867\tbest: 1.1609810 (2)\ttotal: 136ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.160981018\n",
      "bestIteration = 2\n",
      "\n",
      "56:\tloss: 1.1609810\tbest: 0.9812275 (44)\ttotal: 2.65s\tremaining: 837ms\n",
      "0:\tlearn: 1.2588638\ttest: 1.3260773\tbest: 1.3260773 (0)\ttotal: 33ms\tremaining: 132ms\n",
      "1:\tlearn: 1.1497082\ttest: 1.2883887\tbest: 1.2883887 (1)\ttotal: 77.5ms\tremaining: 116ms\n",
      "2:\tlearn: 1.0782001\ttest: 1.2388294\tbest: 1.2388294 (2)\ttotal: 93.3ms\tremaining: 62.2ms\n",
      "3:\tlearn: 1.0039046\ttest: 1.2324835\tbest: 1.2324835 (3)\ttotal: 131ms\tremaining: 32.7ms\n",
      "4:\tlearn: 0.9377918\ttest: 1.2245855\tbest: 1.2245855 (4)\ttotal: 166ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.224585462\n",
      "bestIteration = 4\n",
      "\n",
      "57:\tloss: 1.2245855\tbest: 0.9812275 (44)\ttotal: 2.82s\tremaining: 827ms\n",
      "0:\tlearn: 1.1179606\ttest: 1.2749840\tbest: 1.2749840 (0)\ttotal: 29.6ms\tremaining: 119ms\n",
      "1:\tlearn: 1.0040559\ttest: 1.2305265\tbest: 1.2305265 (1)\ttotal: 63.6ms\tremaining: 95.5ms\n",
      "2:\tlearn: 0.8807103\ttest: 1.1185304\tbest: 1.1185304 (2)\ttotal: 90.4ms\tremaining: 60.2ms\n",
      "3:\tlearn: 0.8120330\ttest: 1.1155942\tbest: 1.1155942 (3)\ttotal: 129ms\tremaining: 32.3ms\n",
      "4:\tlearn: 0.7258546\ttest: 1.0802175\tbest: 1.0802175 (4)\ttotal: 168ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.080217547\n",
      "bestIteration = 4\n",
      "\n",
      "58:\tloss: 1.0802175\tbest: 0.9812275 (44)\ttotal: 2.99s\tremaining: 812ms\n",
      "0:\tlearn: 1.0351628\ttest: 1.2599759\tbest: 1.2599759 (0)\ttotal: 28.3ms\tremaining: 113ms\n",
      "1:\tlearn: 0.9114341\ttest: 1.2243212\tbest: 1.2243212 (1)\ttotal: 62.5ms\tremaining: 93.8ms\n",
      "2:\tlearn: 0.8002168\ttest: 1.1609810\tbest: 1.1609810 (2)\ttotal: 89.2ms\tremaining: 59.4ms\n",
      "3:\tlearn: 0.7010779\ttest: 1.1751867\tbest: 1.1609810 (2)\ttotal: 121ms\tremaining: 30.3ms\n",
      "4:\tlearn: 0.6154554\ttest: 1.1981327\tbest: 1.1609810 (2)\ttotal: 159ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.160981018\n",
      "bestIteration = 2\n",
      "\n",
      "59:\tloss: 1.1609810\tbest: 0.9812275 (44)\ttotal: 3.16s\tremaining: 790ms\n",
      "0:\tlearn: 1.3105130\ttest: 1.3786709\tbest: 1.3786709 (0)\ttotal: 155ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.378670899\n",
      "bestIteration = 0\n",
      "\n",
      "60:\tloss: 1.3786709\tbest: 0.9812275 (44)\ttotal: 3.31s\tremaining: 761ms\n",
      "0:\tlearn: 1.2142873\ttest: 1.3698675\tbest: 1.3698675 (0)\ttotal: 173ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.369867476\n",
      "bestIteration = 0\n",
      "\n",
      "61:\tloss: 1.3698675\tbest: 0.9812275 (44)\ttotal: 3.49s\tremaining: 732ms\n",
      "0:\tlearn: 1.1459147\ttest: 1.3643322\tbest: 1.3643322 (0)\ttotal: 168ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.364332218\n",
      "bestIteration = 0\n",
      "\n",
      "62:\tloss: 1.3643322\tbest: 0.9812275 (44)\ttotal: 3.66s\tremaining: 697ms\n",
      "0:\tlearn: 1.3105130\ttest: 1.3786709\tbest: 1.3786709 (0)\ttotal: 160ms\tremaining: 160ms\n",
      "1:\tlearn: 1.2020218\ttest: 1.3220278\tbest: 1.3220278 (1)\ttotal: 262ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.322027783\n",
      "bestIteration = 1\n",
      "\n",
      "63:\tloss: 1.3220278\tbest: 0.9812275 (44)\ttotal: 3.92s\tremaining: 674ms\n",
      "0:\tlearn: 1.2142873\ttest: 1.3698675\tbest: 1.3698675 (0)\ttotal: 152ms\tremaining: 152ms\n",
      "1:\tlearn: 1.0109037\ttest: 1.2781113\tbest: 1.2781113 (1)\ttotal: 252ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.278111349\n",
      "bestIteration = 1\n",
      "\n",
      "64:\tloss: 1.2781113\tbest: 0.9812275 (44)\ttotal: 4.18s\tremaining: 643ms\n",
      "0:\tlearn: 1.1459147\ttest: 1.3643322\tbest: 1.3643322 (0)\ttotal: 164ms\tremaining: 164ms\n",
      "1:\tlearn: 0.9012549\ttest: 1.2688722\tbest: 1.2688722 (1)\ttotal: 263ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.268872246\n",
      "bestIteration = 1\n",
      "\n",
      "65:\tloss: 1.2688722\tbest: 0.9812275 (44)\ttotal: 4.44s\tremaining: 606ms\n",
      "0:\tlearn: 1.3105130\ttest: 1.3786709\tbest: 1.3786709 (0)\ttotal: 168ms\tremaining: 335ms\n",
      "1:\tlearn: 1.2020218\ttest: 1.3220278\tbest: 1.3220278 (1)\ttotal: 276ms\tremaining: 138ms\n",
      "2:\tlearn: 1.0862690\ttest: 1.2518118\tbest: 1.2518118 (2)\ttotal: 345ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.251811791\n",
      "bestIteration = 2\n",
      "\n",
      "66:\tloss: 1.2518118\tbest: 0.9812275 (44)\ttotal: 4.79s\tremaining: 572ms\n",
      "0:\tlearn: 1.2142873\ttest: 1.3698675\tbest: 1.3698675 (0)\ttotal: 146ms\tremaining: 293ms\n",
      "1:\tlearn: 1.0109037\ttest: 1.2781113\tbest: 1.2781113 (1)\ttotal: 244ms\tremaining: 122ms\n",
      "2:\tlearn: 0.8641643\ttest: 1.1944295\tbest: 1.1944295 (2)\ttotal: 310ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.194429496\n",
      "bestIteration = 2\n",
      "\n",
      "67:\tloss: 1.1944295\tbest: 0.9812275 (44)\ttotal: 5.1s\tremaining: 525ms\n",
      "0:\tlearn: 1.1459147\ttest: 1.3643322\tbest: 1.3643322 (0)\ttotal: 168ms\tremaining: 335ms\n",
      "1:\tlearn: 0.9012549\ttest: 1.2688722\tbest: 1.2688722 (1)\ttotal: 265ms\tremaining: 133ms\n",
      "2:\tlearn: 0.7461393\ttest: 1.1817428\tbest: 1.1817428 (2)\ttotal: 329ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.181742756\n",
      "bestIteration = 2\n",
      "\n",
      "68:\tloss: 1.1817428\tbest: 0.9812275 (44)\ttotal: 5.43s\tremaining: 473ms\n",
      "0:\tlearn: 1.3105130\ttest: 1.3786709\tbest: 1.3786709 (0)\ttotal: 167ms\tremaining: 501ms\n",
      "1:\tlearn: 1.2020218\ttest: 1.3220278\tbest: 1.3220278 (1)\ttotal: 262ms\tremaining: 262ms\n",
      "2:\tlearn: 1.0862690\ttest: 1.2518118\tbest: 1.2518118 (2)\ttotal: 329ms\tremaining: 110ms\n",
      "3:\tlearn: 1.0120448\ttest: 1.1925142\tbest: 1.1925142 (3)\ttotal: 396ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.192514159\n",
      "bestIteration = 3\n",
      "\n",
      "69:\tloss: 1.1925142\tbest: 0.9812275 (44)\ttotal: 5.83s\tremaining: 417ms\n",
      "0:\tlearn: 1.2142873\ttest: 1.3698675\tbest: 1.3698675 (0)\ttotal: 153ms\tremaining: 458ms\n",
      "1:\tlearn: 1.0109037\ttest: 1.2781113\tbest: 1.2781113 (1)\ttotal: 253ms\tremaining: 253ms\n",
      "2:\tlearn: 0.8641643\ttest: 1.1944295\tbest: 1.1944295 (2)\ttotal: 319ms\tremaining: 106ms\n",
      "3:\tlearn: 0.7675489\ttest: 1.1679016\tbest: 1.1679016 (3)\ttotal: 495ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.167901583\n",
      "bestIteration = 3\n",
      "\n",
      "70:\tloss: 1.1679016\tbest: 0.9812275 (44)\ttotal: 6.33s\tremaining: 357ms\n",
      "0:\tlearn: 1.1459147\ttest: 1.3643322\tbest: 1.3643322 (0)\ttotal: 189ms\tremaining: 567ms\n",
      "1:\tlearn: 0.9012549\ttest: 1.2688722\tbest: 1.2688722 (1)\ttotal: 295ms\tremaining: 295ms\n",
      "2:\tlearn: 0.7461393\ttest: 1.1817428\tbest: 1.1817428 (2)\ttotal: 362ms\tremaining: 121ms\n",
      "3:\tlearn: 0.6427184\ttest: 1.1689430\tbest: 1.1689430 (3)\ttotal: 526ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.168943018\n",
      "bestIteration = 3\n",
      "\n",
      "71:\tloss: 1.1689430\tbest: 0.9812275 (44)\ttotal: 6.86s\tremaining: 286ms\n",
      "0:\tlearn: 1.3105130\ttest: 1.3786709\tbest: 1.3786709 (0)\ttotal: 149ms\tremaining: 597ms\n",
      "1:\tlearn: 1.2020218\ttest: 1.3220278\tbest: 1.3220278 (1)\ttotal: 247ms\tremaining: 371ms\n",
      "2:\tlearn: 1.0862690\ttest: 1.2518118\tbest: 1.2518118 (2)\ttotal: 310ms\tremaining: 207ms\n",
      "3:\tlearn: 1.0120448\ttest: 1.1925142\tbest: 1.1925142 (3)\ttotal: 369ms\tremaining: 92.3ms\n",
      "4:\tlearn: 0.9377752\ttest: 1.1423204\tbest: 1.1423204 (4)\ttotal: 384ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.142320361\n",
      "bestIteration = 4\n",
      "\n",
      "72:\tloss: 1.1423204\tbest: 0.9812275 (44)\ttotal: 7.25s\tremaining: 199ms\n",
      "0:\tlearn: 1.2142873\ttest: 1.3698675\tbest: 1.3698675 (0)\ttotal: 147ms\tremaining: 589ms\n",
      "1:\tlearn: 1.0109037\ttest: 1.2781113\tbest: 1.2781113 (1)\ttotal: 249ms\tremaining: 374ms\n",
      "2:\tlearn: 0.8641643\ttest: 1.1944295\tbest: 1.1944295 (2)\ttotal: 312ms\tremaining: 208ms\n",
      "3:\tlearn: 0.7675489\ttest: 1.1679016\tbest: 1.1679016 (3)\ttotal: 484ms\tremaining: 121ms\n",
      "4:\tlearn: 0.6867527\ttest: 1.1508908\tbest: 1.1508908 (4)\ttotal: 642ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.15089077\n",
      "bestIteration = 4\n",
      "\n",
      "73:\tloss: 1.1508908\tbest: 0.9812275 (44)\ttotal: 7.89s\tremaining: 107ms\n",
      "0:\tlearn: 1.1459147\ttest: 1.3643322\tbest: 1.3643322 (0)\ttotal: 154ms\tremaining: 615ms\n",
      "1:\tlearn: 0.9012549\ttest: 1.2688722\tbest: 1.2688722 (1)\ttotal: 252ms\tremaining: 378ms\n",
      "2:\tlearn: 0.7461393\ttest: 1.1817428\tbest: 1.1817428 (2)\ttotal: 314ms\tremaining: 210ms\n",
      "3:\tlearn: 0.6427184\ttest: 1.1689430\tbest: 1.1689430 (3)\ttotal: 466ms\tremaining: 117ms\n",
      "4:\tlearn: 0.5615782\ttest: 1.1661406\tbest: 1.1661406 (4)\ttotal: 634ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.166140575\n",
      "bestIteration = 4\n",
      "\n",
      "74:\tloss: 1.1661406\tbest: 0.9812275 (44)\ttotal: 8.53s\tremaining: 0us\n",
      "Estimating final quality...\n",
      "Training on fold [0/3]\n",
      "0:\tlearn: 1.0313895\ttest: 1.0628785\tbest: 1.0628785 (0)\ttotal: 16.1ms\tremaining: 64.4ms\n",
      "1:\tlearn: 0.9050851\ttest: 1.0817068\tbest: 1.0628785 (0)\ttotal: 33.7ms\tremaining: 50.6ms\n",
      "2:\tlearn: 0.8518581\ttest: 1.0905875\tbest: 1.0628785 (0)\ttotal: 55.4ms\tremaining: 36.9ms\n",
      "3:\tlearn: 0.7607874\ttest: 1.0449476\tbest: 1.0449476 (3)\ttotal: 74.8ms\tremaining: 18.7ms\n",
      "4:\tlearn: 0.6984041\ttest: 1.0645193\tbest: 1.0449476 (3)\ttotal: 93.8ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.044947608\n",
      "bestIteration = 3\n",
      "\n",
      "Training on fold [1/3]\n",
      "0:\tlearn: 1.0256479\ttest: 1.1795774\tbest: 1.1795774 (0)\ttotal: 17.4ms\tremaining: 69.7ms\n",
      "1:\tlearn: 0.9501607\ttest: 1.1615535\tbest: 1.1615535 (1)\ttotal: 35.7ms\tremaining: 53.6ms\n",
      "2:\tlearn: 0.7696262\ttest: 1.0747834\tbest: 1.0747834 (2)\ttotal: 58.1ms\tremaining: 38.7ms\n",
      "3:\tlearn: 0.7454602\ttest: 1.0636860\tbest: 1.0636860 (3)\ttotal: 76.8ms\tremaining: 19.2ms\n",
      "4:\tlearn: 0.7221261\ttest: 1.0743098\tbest: 1.0636860 (3)\ttotal: 97.5ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.06368603\n",
      "bestIteration = 3\n",
      "\n",
      "Training on fold [2/3]\n",
      "0:\tlearn: 1.0416179\ttest: 1.1271060\tbest: 1.1271060 (0)\ttotal: 15.4ms\tremaining: 61.6ms\n",
      "1:\tlearn: 0.9487132\ttest: 1.1256051\tbest: 1.1256051 (1)\ttotal: 30.2ms\tremaining: 45.3ms\n",
      "2:\tlearn: 0.8517053\ttest: 1.0843067\tbest: 1.0843067 (2)\ttotal: 48.9ms\tremaining: 32.6ms\n",
      "3:\tlearn: 0.7608136\ttest: 1.0095352\tbest: 1.0095352 (3)\ttotal: 68ms\tremaining: 17ms\n",
      "4:\tlearn: 0.6967774\ttest: 1.0621982\tbest: 1.0095352 (3)\ttotal: 97.5ms\tremaining: 0us\n",
      "\n",
      "bestTest = 1.009535246\n",
      "bestIteration = 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initiating model\n",
    "cat_model = CatBoostClassifier()\n",
    "\n",
    "# using grid search to determine best parameters\n",
    "grid = {'iterations': [1, 2, 3, 4, 5],\n",
    "        'depth': [1, 2, 4, 6, 10],\n",
    "        'learning_rate': [.3, .7, 1]}\n",
    "\n",
    "# Pooling data before fitting\n",
    "pool_train = Pool(X_train_cb, y_train_cb, cat_features=['Team', 'School', 'Conf'])\n",
    "# running a grid search to determine parameters\n",
    "gs_result = cat_model.grid_search(grid, pool_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pooling test data\n",
    "pool_test = Pool(X_test_cb, y_test_cb, cat_features=['Team', 'School', 'Conf'])\n",
    "\n",
    "# making predictions\n",
    "cat_preds = cat_model.predict(pool_test)\n",
    "cat_proba = cat_model.predict_proba(pool_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.40      0.40      0.40         5\n",
      "         2.0       0.00      0.00      0.00         3\n",
      "         3.0       0.60      0.55      0.57        22\n",
      "         4.0       0.77      0.91      0.83        22\n",
      "\n",
      "    accuracy                           0.65        52\n",
      "   macro avg       0.44      0.46      0.45        52\n",
      "weighted avg       0.62      0.65      0.63        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display(f1_score(y_test_cb, cat_preds, average='macro'))\n",
    "print(classification_report(y_test_cb, cat_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  0,  3,  0],\n",
       "       [ 0,  0,  3,  0],\n",
       "       [ 3,  1, 12,  6],\n",
       "       [ 0,  0,  2, 20]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_cb, cat_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>School</th>\n",
       "      <th>Conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WAS</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>SEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TAM</td>\n",
       "      <td>Fresno St.</td>\n",
       "      <td>WAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PIT</td>\n",
       "      <td>Michigan St.</td>\n",
       "      <td>Big Ten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WAS</td>\n",
       "      <td>Tulsa</td>\n",
       "      <td>Ind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KAN</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>Ind</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team        School     Conf\n",
       "0  WAS     Tennessee      SEC\n",
       "1  TAM    Fresno St.      WAC\n",
       "2  PIT  Michigan St.  Big Ten\n",
       "3  WAS         Tulsa      Ind\n",
       "4  KAN       Memphis      Ind"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a deep learning model to improve score\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>Pick</th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight</th>\n",
       "      <th>40 Time</th>\n",
       "      <th>Height (in)</th>\n",
       "      <th>G</th>\n",
       "      <th>Completions</th>\n",
       "      <th>Attempts</th>\n",
       "      <th>CompletionPCT</th>\n",
       "      <th>...</th>\n",
       "      <th>YardsPerAttempt</th>\n",
       "      <th>AdjustedYardsPerAttempt</th>\n",
       "      <th>PassingTDs</th>\n",
       "      <th>Int</th>\n",
       "      <th>EfficiencyRtg</th>\n",
       "      <th>RushAtt</th>\n",
       "      <th>RushYds</th>\n",
       "      <th>RushAvg</th>\n",
       "      <th>RushTD</th>\n",
       "      <th>YPG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>4.82</td>\n",
       "      <td>74.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>64.6</td>\n",
       "      <td>...</td>\n",
       "      <td>8.259649</td>\n",
       "      <td>8.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>157.3</td>\n",
       "      <td>46.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>22.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>4.82</td>\n",
       "      <td>75.3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>64.1</td>\n",
       "      <td>...</td>\n",
       "      <td>9.593434</td>\n",
       "      <td>10.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>167.2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-113.0</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>316.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>178</td>\n",
       "      <td>23.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>5.13</td>\n",
       "      <td>74.3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.752976</td>\n",
       "      <td>5.8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-160.0</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>197</td>\n",
       "      <td>23.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>5.04</td>\n",
       "      <td>75.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>55.9</td>\n",
       "      <td>...</td>\n",
       "      <td>7.496084</td>\n",
       "      <td>6.8</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>129.1</td>\n",
       "      <td>73.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>261.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>199</td>\n",
       "      <td>23.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>4.82</td>\n",
       "      <td>74.9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>60.8</td>\n",
       "      <td>...</td>\n",
       "      <td>6.945055</td>\n",
       "      <td>5.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>125.3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>210.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Round  Pick   Age  Weight  40 Time  Height (in)     G  Completions  \\\n",
       "0      1     3  22.0   221.0     4.82         74.0  11.0        184.0   \n",
       "1      1     6  22.0   228.0     4.82         75.3  12.0        254.0   \n",
       "2      6   178  23.0   227.0     5.13         74.3  12.0        215.0   \n",
       "3      7   197  23.0   221.0     5.04         75.0  11.0        214.0   \n",
       "4      7   199  23.0   208.0     4.82         74.9   9.0        166.0   \n",
       "\n",
       "   Attempts  CompletionPCT  ...  YardsPerAttempt  AdjustedYardsPerAttempt  \\\n",
       "0     285.0           64.6  ...         8.259649                      8.8   \n",
       "1     396.0           64.1  ...         9.593434                     10.5   \n",
       "2     336.0           64.0  ...         6.752976                      5.8   \n",
       "3     383.0           55.9  ...         7.496084                      6.8   \n",
       "4     273.0           60.8  ...         6.945055                      5.8   \n",
       "\n",
       "   PassingTDs   Int  EfficiencyRtg  RushAtt  RushYds  RushAvg  RushTD  \\\n",
       "0        25.0   8.0          157.3     46.0     73.0      1.6     3.0   \n",
       "1        30.0   5.0          167.2     40.0   -113.0     -2.8     1.0   \n",
       "2         9.0  11.0          123.0     41.0   -160.0     -3.9     0.0   \n",
       "3        21.0  15.0          129.1     73.0     10.0      0.1     1.0   \n",
       "4        13.0  13.0          125.3     38.0   -176.0     -4.6     1.0   \n",
       "\n",
       "          YPG  \n",
       "0  214.000000  \n",
       "1  316.583333  \n",
       "2  189.083333  \n",
       "3  261.000000  \n",
       "4  210.666667  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling numeric data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_data = pd.DataFrame(scaler.fit_transform(df_num), columns = df_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>Pick</th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight</th>\n",
       "      <th>40 Time</th>\n",
       "      <th>Height (in)</th>\n",
       "      <th>G</th>\n",
       "      <th>Completions</th>\n",
       "      <th>Attempts</th>\n",
       "      <th>CompletionPCT</th>\n",
       "      <th>...</th>\n",
       "      <th>YardsPerAttempt</th>\n",
       "      <th>AdjustedYardsPerAttempt</th>\n",
       "      <th>PassingTDs</th>\n",
       "      <th>Int</th>\n",
       "      <th>EfficiencyRtg</th>\n",
       "      <th>RushAtt</th>\n",
       "      <th>RushYds</th>\n",
       "      <th>RushAvg</th>\n",
       "      <th>RushTD</th>\n",
       "      <th>YPG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.316667</td>\n",
       "      <td>-1.387645</td>\n",
       "      <td>-0.832815</td>\n",
       "      <td>-0.144257</td>\n",
       "      <td>-0.031180</td>\n",
       "      <td>-0.686386</td>\n",
       "      <td>-1.782153</td>\n",
       "      <td>-1.585677</td>\n",
       "      <td>-1.696893</td>\n",
       "      <td>-1.636305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455390</td>\n",
       "      <td>0.739926</td>\n",
       "      <td>-1.207959</td>\n",
       "      <td>-1.413694</td>\n",
       "      <td>-1.589380</td>\n",
       "      <td>-1.240042</td>\n",
       "      <td>-0.407914</td>\n",
       "      <td>-0.057434</td>\n",
       "      <td>-0.752009</td>\n",
       "      <td>-0.597331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.316667</td>\n",
       "      <td>-1.350505</td>\n",
       "      <td>-0.832815</td>\n",
       "      <td>0.490262</td>\n",
       "      <td>-0.031180</td>\n",
       "      <td>0.131743</td>\n",
       "      <td>-1.688662</td>\n",
       "      <td>-1.300034</td>\n",
       "      <td>-1.405877</td>\n",
       "      <td>-1.645713</td>\n",
       "      <td>...</td>\n",
       "      <td>2.075590</td>\n",
       "      <td>2.142279</td>\n",
       "      <td>-1.006030</td>\n",
       "      <td>-1.677415</td>\n",
       "      <td>-1.507561</td>\n",
       "      <td>-1.291921</td>\n",
       "      <td>-0.701872</td>\n",
       "      <td>-0.736074</td>\n",
       "      <td>-1.020062</td>\n",
       "      <td>1.554892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.963545</td>\n",
       "      <td>0.778819</td>\n",
       "      <td>0.181562</td>\n",
       "      <td>0.399616</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>-0.497587</td>\n",
       "      <td>-1.688662</td>\n",
       "      <td>-1.459178</td>\n",
       "      <td>-1.563183</td>\n",
       "      <td>-1.647595</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.374823</td>\n",
       "      <td>-1.734814</td>\n",
       "      <td>-1.854132</td>\n",
       "      <td>-1.149973</td>\n",
       "      <td>-1.872854</td>\n",
       "      <td>-1.283274</td>\n",
       "      <td>-0.776152</td>\n",
       "      <td>-0.905735</td>\n",
       "      <td>-1.154089</td>\n",
       "      <td>-1.120088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.419587</td>\n",
       "      <td>1.014035</td>\n",
       "      <td>0.181562</td>\n",
       "      <td>-0.144257</td>\n",
       "      <td>1.335430</td>\n",
       "      <td>-0.057056</td>\n",
       "      <td>-1.782153</td>\n",
       "      <td>-1.463259</td>\n",
       "      <td>-1.439960</td>\n",
       "      <td>-1.800001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.472143</td>\n",
       "      <td>-0.909901</td>\n",
       "      <td>-1.369502</td>\n",
       "      <td>-0.798346</td>\n",
       "      <td>-1.822441</td>\n",
       "      <td>-1.006588</td>\n",
       "      <td>-0.507480</td>\n",
       "      <td>-0.288788</td>\n",
       "      <td>-1.020062</td>\n",
       "      <td>0.388741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.419587</td>\n",
       "      <td>1.038795</td>\n",
       "      <td>0.181562</td>\n",
       "      <td>-1.322649</td>\n",
       "      <td>-0.031180</td>\n",
       "      <td>-0.119989</td>\n",
       "      <td>-1.969136</td>\n",
       "      <td>-1.659129</td>\n",
       "      <td>-1.728354</td>\n",
       "      <td>-1.707805</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.141498</td>\n",
       "      <td>-1.734814</td>\n",
       "      <td>-1.692589</td>\n",
       "      <td>-0.974159</td>\n",
       "      <td>-1.853846</td>\n",
       "      <td>-1.309214</td>\n",
       "      <td>-0.801438</td>\n",
       "      <td>-1.013700</td>\n",
       "      <td>-1.020062</td>\n",
       "      <td>-0.667265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>-0.860625</td>\n",
       "      <td>-0.632477</td>\n",
       "      <td>0.181562</td>\n",
       "      <td>1.215426</td>\n",
       "      <td>1.708142</td>\n",
       "      <td>1.201604</td>\n",
       "      <td>-0.566768</td>\n",
       "      <td>-0.141139</td>\n",
       "      <td>-0.370281</td>\n",
       "      <td>-0.296635</td>\n",
       "      <td>...</td>\n",
       "      <td>1.515971</td>\n",
       "      <td>1.696972</td>\n",
       "      <td>0.528629</td>\n",
       "      <td>-0.798346</td>\n",
       "      <td>-0.111678</td>\n",
       "      <td>-0.539680</td>\n",
       "      <td>-0.431620</td>\n",
       "      <td>-0.165399</td>\n",
       "      <td>-0.215903</td>\n",
       "      <td>1.227950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>-0.404582</td>\n",
       "      <td>-0.607718</td>\n",
       "      <td>-0.832815</td>\n",
       "      <td>0.037034</td>\n",
       "      <td>-0.031180</td>\n",
       "      <td>-0.057056</td>\n",
       "      <td>1.490039</td>\n",
       "      <td>0.932064</td>\n",
       "      <td>1.116259</td>\n",
       "      <td>1.545412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.936106</td>\n",
       "      <td>-0.516336</td>\n",
       "      <td>0.649787</td>\n",
       "      <td>0.256538</td>\n",
       "      <td>1.423050</td>\n",
       "      <td>2.149366</td>\n",
       "      <td>2.019609</td>\n",
       "      <td>2.009336</td>\n",
       "      <td>1.794496</td>\n",
       "      <td>-0.680795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>-0.404582</td>\n",
       "      <td>-0.595338</td>\n",
       "      <td>-0.832815</td>\n",
       "      <td>-0.506839</td>\n",
       "      <td>-0.031180</td>\n",
       "      <td>-0.057056</td>\n",
       "      <td>-2.343100</td>\n",
       "      <td>-1.810111</td>\n",
       "      <td>-1.932851</td>\n",
       "      <td>-1.606200</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.183946</td>\n",
       "      <td>-0.084987</td>\n",
       "      <td>-1.934903</td>\n",
       "      <td>-1.853229</td>\n",
       "      <td>-1.733183</td>\n",
       "      <td>-1.378385</td>\n",
       "      <td>-0.464809</td>\n",
       "      <td>-0.119128</td>\n",
       "      <td>-0.752009</td>\n",
       "      <td>1.240538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0.051460</td>\n",
       "      <td>0.221728</td>\n",
       "      <td>0.181562</td>\n",
       "      <td>-1.050712</td>\n",
       "      <td>-1.087197</td>\n",
       "      <td>-1.945046</td>\n",
       "      <td>0.461636</td>\n",
       "      <td>0.446470</td>\n",
       "      <td>0.350704</td>\n",
       "      <td>0.779617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098961</td>\n",
       "      <td>0.547627</td>\n",
       "      <td>0.528629</td>\n",
       "      <td>-0.710439</td>\n",
       "      <td>0.808167</td>\n",
       "      <td>1.155024</td>\n",
       "      <td>1.548644</td>\n",
       "      <td>1.546626</td>\n",
       "      <td>1.124363</td>\n",
       "      <td>0.003304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.963545</td>\n",
       "      <td>1.274011</td>\n",
       "      <td>-0.832815</td>\n",
       "      <td>-0.234902</td>\n",
       "      <td>0.093057</td>\n",
       "      <td>-1.315716</td>\n",
       "      <td>0.648618</td>\n",
       "      <td>0.785162</td>\n",
       "      <td>0.704642</td>\n",
       "      <td>0.725052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051989</td>\n",
       "      <td>0.551728</td>\n",
       "      <td>1.134416</td>\n",
       "      <td>-0.358811</td>\n",
       "      <td>0.823870</td>\n",
       "      <td>2.166659</td>\n",
       "      <td>1.882113</td>\n",
       "      <td>1.284424</td>\n",
       "      <td>3.000735</td>\n",
       "      <td>0.311624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Round      Pick       Age    Weight   40 Time  Height (in)         G  \\\n",
       "0   -1.316667 -1.387645 -0.832815 -0.144257 -0.031180    -0.686386 -1.782153   \n",
       "1   -1.316667 -1.350505 -0.832815  0.490262 -0.031180     0.131743 -1.688662   \n",
       "2    0.963545  0.778819  0.181562  0.399616  1.894498    -0.497587 -1.688662   \n",
       "3    1.419587  1.014035  0.181562 -0.144257  1.335430    -0.057056 -1.782153   \n",
       "4    1.419587  1.038795  0.181562 -1.322649 -0.031180    -0.119989 -1.969136   \n",
       "..        ...       ...       ...       ...       ...          ...       ...   \n",
       "252 -0.860625 -0.632477  0.181562  1.215426  1.708142     1.201604 -0.566768   \n",
       "253 -0.404582 -0.607718 -0.832815  0.037034 -0.031180    -0.057056  1.490039   \n",
       "254 -0.404582 -0.595338 -0.832815 -0.506839 -0.031180    -0.057056 -2.343100   \n",
       "255  0.051460  0.221728  0.181562 -1.050712 -1.087197    -1.945046  0.461636   \n",
       "256  0.963545  1.274011 -0.832815 -0.234902  0.093057    -1.315716  0.648618   \n",
       "\n",
       "     Completions  Attempts  CompletionPCT  ...  YardsPerAttempt  \\\n",
       "0      -1.585677 -1.696893      -1.636305  ...         0.455390   \n",
       "1      -1.300034 -1.405877      -1.645713  ...         2.075590   \n",
       "2      -1.459178 -1.563183      -1.647595  ...        -1.374823   \n",
       "3      -1.463259 -1.439960      -1.800001  ...        -0.472143   \n",
       "4      -1.659129 -1.728354      -1.707805  ...        -1.141498   \n",
       "..           ...       ...            ...  ...              ...   \n",
       "252    -0.141139 -0.370281      -0.296635  ...         1.515971   \n",
       "253     0.932064  1.116259       1.545412  ...        -0.936106   \n",
       "254    -1.810111 -1.932851      -1.606200  ...        -0.183946   \n",
       "255     0.446470  0.350704       0.779617  ...         0.098961   \n",
       "256     0.785162  0.704642       0.725052  ...         0.051989   \n",
       "\n",
       "     AdjustedYardsPerAttempt  PassingTDs       Int  EfficiencyRtg   RushAtt  \\\n",
       "0                   0.739926   -1.207959 -1.413694      -1.589380 -1.240042   \n",
       "1                   2.142279   -1.006030 -1.677415      -1.507561 -1.291921   \n",
       "2                  -1.734814   -1.854132 -1.149973      -1.872854 -1.283274   \n",
       "3                  -0.909901   -1.369502 -0.798346      -1.822441 -1.006588   \n",
       "4                  -1.734814   -1.692589 -0.974159      -1.853846 -1.309214   \n",
       "..                       ...         ...       ...            ...       ...   \n",
       "252                 1.696972    0.528629 -0.798346      -0.111678 -0.539680   \n",
       "253                -0.516336    0.649787  0.256538       1.423050  2.149366   \n",
       "254                -0.084987   -1.934903 -1.853229      -1.733183 -1.378385   \n",
       "255                 0.547627    0.528629 -0.710439       0.808167  1.155024   \n",
       "256                 0.551728    1.134416 -0.358811       0.823870  2.166659   \n",
       "\n",
       "      RushYds   RushAvg    RushTD       YPG  \n",
       "0   -0.407914 -0.057434 -0.752009 -0.597331  \n",
       "1   -0.701872 -0.736074 -1.020062  1.554892  \n",
       "2   -0.776152 -0.905735 -1.154089 -1.120088  \n",
       "3   -0.507480 -0.288788 -1.020062  0.388741  \n",
       "4   -0.801438 -1.013700 -1.020062 -0.667265  \n",
       "..        ...       ...       ...       ...  \n",
       "252 -0.431620 -0.165399 -0.215903  1.227950  \n",
       "253  2.019609  2.009336  1.794496 -0.680795  \n",
       "254 -0.464809 -0.119128 -0.752009  1.240538  \n",
       "255  1.548644  1.546626  1.124363  0.003304  \n",
       "256  1.882113  1.284424  3.000735  0.311624  \n",
       "\n",
       "[257 rows x 21 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_ARI</th>\n",
       "      <th>Team_ATL</th>\n",
       "      <th>Team_BAL</th>\n",
       "      <th>Team_BUF</th>\n",
       "      <th>Team_CAR</th>\n",
       "      <th>Team_CHI</th>\n",
       "      <th>Team_CIN</th>\n",
       "      <th>Team_CLE</th>\n",
       "      <th>Team_DAL</th>\n",
       "      <th>Team_DEN</th>\n",
       "      <th>...</th>\n",
       "      <th>Conf_Big West</th>\n",
       "      <th>Conf_CUSA</th>\n",
       "      <th>Conf_Ind</th>\n",
       "      <th>Conf_MAC</th>\n",
       "      <th>Conf_MWC</th>\n",
       "      <th>Conf_Pac-10</th>\n",
       "      <th>Conf_Pac-12</th>\n",
       "      <th>Conf_SEC</th>\n",
       "      <th>Conf_Sun Belt</th>\n",
       "      <th>Conf_WAC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257 rows × 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Team_ARI  Team_ATL  Team_BAL  Team_BUF  Team_CAR  Team_CHI  Team_CIN  \\\n",
       "0         0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1         0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2         0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3         0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4         0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "252       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "253       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "254       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "255       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "256       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "     Team_CLE  Team_DAL  Team_DEN  ...  Conf_Big West  Conf_CUSA  Conf_Ind  \\\n",
       "0         0.0       0.0       0.0  ...            0.0        0.0       0.0   \n",
       "1         0.0       0.0       0.0  ...            0.0        0.0       0.0   \n",
       "2         0.0       0.0       0.0  ...            0.0        0.0       0.0   \n",
       "3         0.0       0.0       0.0  ...            0.0        0.0       1.0   \n",
       "4         0.0       0.0       0.0  ...            0.0        0.0       1.0   \n",
       "..        ...       ...       ...  ...            ...        ...       ...   \n",
       "252       0.0       0.0       0.0  ...            0.0        0.0       0.0   \n",
       "253       0.0       0.0       0.0  ...            0.0        0.0       0.0   \n",
       "254       0.0       0.0       0.0  ...            0.0        0.0       0.0   \n",
       "255       0.0       0.0       0.0  ...            0.0        0.0       0.0   \n",
       "256       0.0       0.0       0.0  ...            0.0        0.0       0.0   \n",
       "\n",
       "     Conf_MAC  Conf_MWC  Conf_Pac-10  Conf_Pac-12  Conf_SEC  Conf_Sun Belt  \\\n",
       "0         0.0       0.0          0.0          0.0       1.0            0.0   \n",
       "1         0.0       0.0          0.0          0.0       0.0            0.0   \n",
       "2         0.0       0.0          0.0          0.0       0.0            0.0   \n",
       "3         0.0       0.0          0.0          0.0       0.0            0.0   \n",
       "4         0.0       0.0          0.0          0.0       0.0            0.0   \n",
       "..        ...       ...          ...          ...       ...            ...   \n",
       "252       0.0       0.0          0.0          0.0       1.0            0.0   \n",
       "253       0.0       0.0          0.0          0.0       1.0            0.0   \n",
       "254       0.0       0.0          0.0          1.0       0.0            0.0   \n",
       "255       0.0       0.0          0.0          0.0       0.0            0.0   \n",
       "256       0.0       0.0          0.0          0.0       0.0            0.0   \n",
       "\n",
       "     Conf_WAC  \n",
       "0         0.0  \n",
       "1         1.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  \n",
       "..        ...  \n",
       "252       0.0  \n",
       "253       0.0  \n",
       "254       0.0  \n",
       "255       0.0  \n",
       "256       0.0  \n",
       "\n",
       "[257 rows x 142 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding categorigcal variables\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "encoded_data = pd.DataFrame(ohe.fit_transform(df_cat))\n",
    "encoded_data.columns = ohe.get_feature_names_out()\n",
    "\n",
    "encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Round</th>\n",
       "      <th>Pick</th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight</th>\n",
       "      <th>40 Time</th>\n",
       "      <th>Height (in)</th>\n",
       "      <th>G</th>\n",
       "      <th>Completions</th>\n",
       "      <th>Attempts</th>\n",
       "      <th>CompletionPCT</th>\n",
       "      <th>...</th>\n",
       "      <th>Conf_CUSA</th>\n",
       "      <th>Conf_Ind</th>\n",
       "      <th>Conf_MAC</th>\n",
       "      <th>Conf_MWC</th>\n",
       "      <th>Conf_Pac-10</th>\n",
       "      <th>Conf_Pac-12</th>\n",
       "      <th>Conf_SEC</th>\n",
       "      <th>Conf_Sun Belt</th>\n",
       "      <th>Conf_WAC</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.316667</td>\n",
       "      <td>-1.387645</td>\n",
       "      <td>-0.832815</td>\n",
       "      <td>-0.144257</td>\n",
       "      <td>-0.031180</td>\n",
       "      <td>-0.686386</td>\n",
       "      <td>-1.782153</td>\n",
       "      <td>-1.585677</td>\n",
       "      <td>-1.696893</td>\n",
       "      <td>-1.636305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.316667</td>\n",
       "      <td>-1.350505</td>\n",
       "      <td>-0.832815</td>\n",
       "      <td>0.490262</td>\n",
       "      <td>-0.031180</td>\n",
       "      <td>0.131743</td>\n",
       "      <td>-1.688662</td>\n",
       "      <td>-1.300034</td>\n",
       "      <td>-1.405877</td>\n",
       "      <td>-1.645713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.963545</td>\n",
       "      <td>0.778819</td>\n",
       "      <td>0.181562</td>\n",
       "      <td>0.399616</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>-0.497587</td>\n",
       "      <td>-1.688662</td>\n",
       "      <td>-1.459178</td>\n",
       "      <td>-1.563183</td>\n",
       "      <td>-1.647595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.419587</td>\n",
       "      <td>1.014035</td>\n",
       "      <td>0.181562</td>\n",
       "      <td>-0.144257</td>\n",
       "      <td>1.335430</td>\n",
       "      <td>-0.057056</td>\n",
       "      <td>-1.782153</td>\n",
       "      <td>-1.463259</td>\n",
       "      <td>-1.439960</td>\n",
       "      <td>-1.800001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.419587</td>\n",
       "      <td>1.038795</td>\n",
       "      <td>0.181562</td>\n",
       "      <td>-1.322649</td>\n",
       "      <td>-0.031180</td>\n",
       "      <td>-0.119989</td>\n",
       "      <td>-1.969136</td>\n",
       "      <td>-1.659129</td>\n",
       "      <td>-1.728354</td>\n",
       "      <td>-1.707805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Round      Pick       Age    Weight   40 Time  Height (in)         G  \\\n",
       "0 -1.316667 -1.387645 -0.832815 -0.144257 -0.031180    -0.686386 -1.782153   \n",
       "1 -1.316667 -1.350505 -0.832815  0.490262 -0.031180     0.131743 -1.688662   \n",
       "2  0.963545  0.778819  0.181562  0.399616  1.894498    -0.497587 -1.688662   \n",
       "3  1.419587  1.014035  0.181562 -0.144257  1.335430    -0.057056 -1.782153   \n",
       "4  1.419587  1.038795  0.181562 -1.322649 -0.031180    -0.119989 -1.969136   \n",
       "\n",
       "   Completions  Attempts  CompletionPCT  ...  Conf_CUSA  Conf_Ind  Conf_MAC  \\\n",
       "0    -1.585677 -1.696893      -1.636305  ...        0.0       0.0       0.0   \n",
       "1    -1.300034 -1.405877      -1.645713  ...        0.0       0.0       0.0   \n",
       "2    -1.459178 -1.563183      -1.647595  ...        0.0       0.0       0.0   \n",
       "3    -1.463259 -1.439960      -1.800001  ...        0.0       1.0       0.0   \n",
       "4    -1.659129 -1.728354      -1.707805  ...        0.0       1.0       0.0   \n",
       "\n",
       "   Conf_MWC  Conf_Pac-10  Conf_Pac-12  Conf_SEC  Conf_Sun Belt  Conf_WAC  \\\n",
       "0       0.0          0.0          0.0       1.0            0.0       0.0   \n",
       "1       0.0          0.0          0.0       0.0            0.0       1.0   \n",
       "2       0.0          0.0          0.0       0.0            0.0       0.0   \n",
       "3       0.0          0.0          0.0       0.0            0.0       0.0   \n",
       "4       0.0          0.0          0.0       0.0            0.0       0.0   \n",
       "\n",
       "   response  \n",
       "0       3.0  \n",
       "1       3.0  \n",
       "2       3.0  \n",
       "3       3.0  \n",
       "4       4.0  \n",
       "\n",
       "[5 rows x 164 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combining the dataframes\n",
    "working_df = scaled_data.merge(encoded_data, left_index=True, right_index=True)\n",
    "working_df['response'] = response\n",
    "working_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating training and testing data for remaining models\n",
    "X_train, X_test, y_train, y_test = train_test_split(working_df.drop(columns='response'),working_df['response'], test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling sequential model, with relu as activation function and softmax as output layer\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(50, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 1s 29ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n"
     ]
    }
   ],
   "source": [
    "# fitting the model\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca_comp_0</th>\n",
       "      <th>pca_comp_1</th>\n",
       "      <th>pca_comp_2</th>\n",
       "      <th>pca_comp_3</th>\n",
       "      <th>pca_comp_4</th>\n",
       "      <th>pca_comp_5</th>\n",
       "      <th>pca_comp_6</th>\n",
       "      <th>pca_comp_7</th>\n",
       "      <th>pca_comp_8</th>\n",
       "      <th>pca_comp_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_comp_29</th>\n",
       "      <th>pca_comp_30</th>\n",
       "      <th>pca_comp_31</th>\n",
       "      <th>pca_comp_32</th>\n",
       "      <th>pca_comp_33</th>\n",
       "      <th>pca_comp_34</th>\n",
       "      <th>pca_comp_35</th>\n",
       "      <th>pca_comp_36</th>\n",
       "      <th>pca_comp_37</th>\n",
       "      <th>pca_comp_38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.544895</td>\n",
       "      <td>-0.977905</td>\n",
       "      <td>1.874827</td>\n",
       "      <td>-0.637310</td>\n",
       "      <td>-1.490751</td>\n",
       "      <td>-0.486049</td>\n",
       "      <td>-0.041333</td>\n",
       "      <td>0.546840</td>\n",
       "      <td>0.429470</td>\n",
       "      <td>-0.185820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256899</td>\n",
       "      <td>-0.168792</td>\n",
       "      <td>-0.154578</td>\n",
       "      <td>-0.134651</td>\n",
       "      <td>-0.106037</td>\n",
       "      <td>0.067100</td>\n",
       "      <td>-0.246963</td>\n",
       "      <td>0.033826</td>\n",
       "      <td>0.102572</td>\n",
       "      <td>0.241463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.103712</td>\n",
       "      <td>-0.267222</td>\n",
       "      <td>4.270426</td>\n",
       "      <td>0.578306</td>\n",
       "      <td>-0.263666</td>\n",
       "      <td>0.323026</td>\n",
       "      <td>0.018934</td>\n",
       "      <td>0.037947</td>\n",
       "      <td>0.198868</td>\n",
       "      <td>0.520665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464112</td>\n",
       "      <td>0.463209</td>\n",
       "      <td>-0.052250</td>\n",
       "      <td>-0.122312</td>\n",
       "      <td>-0.286476</td>\n",
       "      <td>-0.239502</td>\n",
       "      <td>0.046862</td>\n",
       "      <td>-0.223994</td>\n",
       "      <td>-0.506327</td>\n",
       "      <td>0.252978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.155768</td>\n",
       "      <td>1.739608</td>\n",
       "      <td>-2.016996</td>\n",
       "      <td>-0.927545</td>\n",
       "      <td>-0.194698</td>\n",
       "      <td>0.063367</td>\n",
       "      <td>0.170626</td>\n",
       "      <td>1.438809</td>\n",
       "      <td>0.706235</td>\n",
       "      <td>-0.525907</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232675</td>\n",
       "      <td>0.548283</td>\n",
       "      <td>0.198857</td>\n",
       "      <td>0.159088</td>\n",
       "      <td>0.106818</td>\n",
       "      <td>0.368538</td>\n",
       "      <td>0.278345</td>\n",
       "      <td>-0.334406</td>\n",
       "      <td>-0.054928</td>\n",
       "      <td>-0.056559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.632267</td>\n",
       "      <td>1.193098</td>\n",
       "      <td>-1.157548</td>\n",
       "      <td>0.345012</td>\n",
       "      <td>0.308780</td>\n",
       "      <td>1.215938</td>\n",
       "      <td>0.363852</td>\n",
       "      <td>0.925609</td>\n",
       "      <td>0.231171</td>\n",
       "      <td>-0.120042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040806</td>\n",
       "      <td>-0.259651</td>\n",
       "      <td>0.213716</td>\n",
       "      <td>-0.123893</td>\n",
       "      <td>0.007689</td>\n",
       "      <td>-0.004977</td>\n",
       "      <td>-0.007147</td>\n",
       "      <td>0.055553</td>\n",
       "      <td>-0.150895</td>\n",
       "      <td>-0.148720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.314204</td>\n",
       "      <td>1.100816</td>\n",
       "      <td>-2.315533</td>\n",
       "      <td>0.028236</td>\n",
       "      <td>-1.055464</td>\n",
       "      <td>0.727827</td>\n",
       "      <td>0.077332</td>\n",
       "      <td>-0.199024</td>\n",
       "      <td>-0.510160</td>\n",
       "      <td>0.292038</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.203815</td>\n",
       "      <td>-0.089247</td>\n",
       "      <td>0.508171</td>\n",
       "      <td>0.386664</td>\n",
       "      <td>0.073026</td>\n",
       "      <td>-0.193674</td>\n",
       "      <td>0.274144</td>\n",
       "      <td>-0.306331</td>\n",
       "      <td>0.107988</td>\n",
       "      <td>-0.210368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>-0.655878</td>\n",
       "      <td>0.796030</td>\n",
       "      <td>3.236848</td>\n",
       "      <td>0.351007</td>\n",
       "      <td>1.608051</td>\n",
       "      <td>-0.233360</td>\n",
       "      <td>0.352184</td>\n",
       "      <td>1.218981</td>\n",
       "      <td>-0.006387</td>\n",
       "      <td>-0.168502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050826</td>\n",
       "      <td>-0.062773</td>\n",
       "      <td>-0.385606</td>\n",
       "      <td>0.043151</td>\n",
       "      <td>-0.390329</td>\n",
       "      <td>0.025688</td>\n",
       "      <td>0.226566</td>\n",
       "      <td>0.043678</td>\n",
       "      <td>-0.166239</td>\n",
       "      <td>0.194128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>3.946892</td>\n",
       "      <td>-2.738569</td>\n",
       "      <td>-1.125164</td>\n",
       "      <td>-1.430334</td>\n",
       "      <td>0.275748</td>\n",
       "      <td>0.062216</td>\n",
       "      <td>-0.260640</td>\n",
       "      <td>0.999664</td>\n",
       "      <td>-0.252428</td>\n",
       "      <td>-0.847270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090796</td>\n",
       "      <td>-0.034266</td>\n",
       "      <td>-0.025148</td>\n",
       "      <td>-0.056369</td>\n",
       "      <td>-0.014489</td>\n",
       "      <td>-0.165137</td>\n",
       "      <td>-0.110195</td>\n",
       "      <td>-0.224423</td>\n",
       "      <td>0.085161</td>\n",
       "      <td>0.107766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>-5.345066</td>\n",
       "      <td>-0.294960</td>\n",
       "      <td>1.225778</td>\n",
       "      <td>-0.400822</td>\n",
       "      <td>-1.087206</td>\n",
       "      <td>1.405412</td>\n",
       "      <td>0.340904</td>\n",
       "      <td>0.300319</td>\n",
       "      <td>-0.352459</td>\n",
       "      <td>-0.200551</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010451</td>\n",
       "      <td>0.041288</td>\n",
       "      <td>0.094207</td>\n",
       "      <td>0.064713</td>\n",
       "      <td>-0.146047</td>\n",
       "      <td>-0.318180</td>\n",
       "      <td>-0.199158</td>\n",
       "      <td>0.010333</td>\n",
       "      <td>0.138370</td>\n",
       "      <td>0.057904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1.802894</td>\n",
       "      <td>-2.962190</td>\n",
       "      <td>-0.741076</td>\n",
       "      <td>1.485159</td>\n",
       "      <td>-0.635017</td>\n",
       "      <td>0.086714</td>\n",
       "      <td>0.250346</td>\n",
       "      <td>-0.042538</td>\n",
       "      <td>0.138210</td>\n",
       "      <td>-0.843826</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134340</td>\n",
       "      <td>-0.018855</td>\n",
       "      <td>-0.087045</td>\n",
       "      <td>-0.126435</td>\n",
       "      <td>-0.044435</td>\n",
       "      <td>-0.012229</td>\n",
       "      <td>-0.008139</td>\n",
       "      <td>0.074265</td>\n",
       "      <td>-0.150620</td>\n",
       "      <td>-0.031288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2.947467</td>\n",
       "      <td>-3.102511</td>\n",
       "      <td>-1.260855</td>\n",
       "      <td>1.357572</td>\n",
       "      <td>1.251785</td>\n",
       "      <td>1.561060</td>\n",
       "      <td>-0.473447</td>\n",
       "      <td>1.207801</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.065143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087479</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>-0.284598</td>\n",
       "      <td>0.253104</td>\n",
       "      <td>0.028982</td>\n",
       "      <td>0.115023</td>\n",
       "      <td>0.298358</td>\n",
       "      <td>0.017312</td>\n",
       "      <td>0.013797</td>\n",
       "      <td>0.204664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pca_comp_0  pca_comp_1  pca_comp_2  pca_comp_3  pca_comp_4  pca_comp_5  \\\n",
       "0     -4.544895   -0.977905    1.874827   -0.637310   -1.490751   -0.486049   \n",
       "1     -4.103712   -0.267222    4.270426    0.578306   -0.263666    0.323026   \n",
       "2     -5.155768    1.739608   -2.016996   -0.927545   -0.194698    0.063367   \n",
       "3     -4.632267    1.193098   -1.157548    0.345012    0.308780    1.215938   \n",
       "4     -5.314204    1.100816   -2.315533    0.028236   -1.055464    0.727827   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "252   -0.655878    0.796030    3.236848    0.351007    1.608051   -0.233360   \n",
       "253    3.946892   -2.738569   -1.125164   -1.430334    0.275748    0.062216   \n",
       "254   -5.345066   -0.294960    1.225778   -0.400822   -1.087206    1.405412   \n",
       "255    1.802894   -2.962190   -0.741076    1.485159   -0.635017    0.086714   \n",
       "256    2.947467   -3.102511   -1.260855    1.357572    1.251785    1.561060   \n",
       "\n",
       "     pca_comp_6  pca_comp_7  pca_comp_8  pca_comp_9  ...  pca_comp_29  \\\n",
       "0     -0.041333    0.546840    0.429470   -0.185820  ...     0.256899   \n",
       "1      0.018934    0.037947    0.198868    0.520665  ...     0.464112   \n",
       "2      0.170626    1.438809    0.706235   -0.525907  ...    -0.232675   \n",
       "3      0.363852    0.925609    0.231171   -0.120042  ...     0.040806   \n",
       "4      0.077332   -0.199024   -0.510160    0.292038  ...    -0.203815   \n",
       "..          ...         ...         ...         ...  ...          ...   \n",
       "252    0.352184    1.218981   -0.006387   -0.168502  ...     0.050826   \n",
       "253   -0.260640    0.999664   -0.252428   -0.847270  ...    -0.090796   \n",
       "254    0.340904    0.300319   -0.352459   -0.200551  ...    -0.010451   \n",
       "255    0.250346   -0.042538    0.138210   -0.843826  ...    -0.134340   \n",
       "256   -0.473447    1.207801    0.304878    0.065143  ...     0.087479   \n",
       "\n",
       "     pca_comp_30  pca_comp_31  pca_comp_32  pca_comp_33  pca_comp_34  \\\n",
       "0      -0.168792    -0.154578    -0.134651    -0.106037     0.067100   \n",
       "1       0.463209    -0.052250    -0.122312    -0.286476    -0.239502   \n",
       "2       0.548283     0.198857     0.159088     0.106818     0.368538   \n",
       "3      -0.259651     0.213716    -0.123893     0.007689    -0.004977   \n",
       "4      -0.089247     0.508171     0.386664     0.073026    -0.193674   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "252    -0.062773    -0.385606     0.043151    -0.390329     0.025688   \n",
       "253    -0.034266    -0.025148    -0.056369    -0.014489    -0.165137   \n",
       "254     0.041288     0.094207     0.064713    -0.146047    -0.318180   \n",
       "255    -0.018855    -0.087045    -0.126435    -0.044435    -0.012229   \n",
       "256     0.002024    -0.284598     0.253104     0.028982     0.115023   \n",
       "\n",
       "     pca_comp_35  pca_comp_36  pca_comp_37  pca_comp_38  \n",
       "0      -0.246963     0.033826     0.102572     0.241463  \n",
       "1       0.046862    -0.223994    -0.506327     0.252978  \n",
       "2       0.278345    -0.334406    -0.054928    -0.056559  \n",
       "3      -0.007147     0.055553    -0.150895    -0.148720  \n",
       "4       0.274144    -0.306331     0.107988    -0.210368  \n",
       "..           ...          ...          ...          ...  \n",
       "252     0.226566     0.043678    -0.166239     0.194128  \n",
       "253    -0.110195    -0.224423     0.085161     0.107766  \n",
       "254    -0.199158     0.010333     0.138370     0.057904  \n",
       "255    -0.008139     0.074265    -0.150620    -0.031288  \n",
       "256     0.298358     0.017312     0.013797     0.204664  \n",
       "\n",
       "[257 rows x 39 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using pca to reduce dimensions\n",
    "pca = PCA()\n",
    "\n",
    "# reducing dimensionality while keeping 90% variance\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "# fitting and transforming the data\n",
    "X_reduced = pd.DataFrame(pca.fit_transform(working_df.drop(columns='response')), columns=['pca_comp_%i' % i for i in range(39)])\n",
    "\n",
    "X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting pca reduced data\n",
    "X_train_reduced, X_test_reduced, y_train, y_test = train_test_split(X_reduced, working_df['response'], test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling sequential model, with relu as activation function and softmax as output layer\n",
    "model1 = keras.models.Sequential([\n",
    "    keras.layers.Dense(200, input_dim=39, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying a deep learning model with reduced data\n",
    "model1.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1073 - val_loss: 0.0000e+00 - val_accuracy: 0.0769\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit(X_train_reduced, y_train, epochs=20, validation_data=(X_test_reduced,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a non scaled, encoded df\n",
    "ns_data = df_num.merge(encoded_data, left_index=True, right_index=True)\n",
    "\n",
    "# creating training and testing data \n",
    "X_train_ns, X_test_ns, y_train_ns, y_test_ns = train_test_split(ns_data,working_df['response'], test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating another reduced dataset for non scaled numeric values\n",
    "reduced_ns = pd.DataFrame(pca.fit_transform(ns_data))\n",
    "\n",
    "# creating training and testing data \n",
    "X_train_reduced_ns, X_test_reduced_ns, y_train_ns, y_test_ns = train_test_split(reduced_ns ,working_df['response'], test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         4\n",
      "         2.0       0.00      0.00      0.00         4\n",
      "         3.0       0.52      0.57      0.54        23\n",
      "         4.0       0.38      0.48      0.43        21\n",
      "\n",
      "    accuracy                           0.44        52\n",
      "   macro avg       0.23      0.26      0.24        52\n",
      "weighted avg       0.39      0.44      0.41        52\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\billy\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\billy\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\billy\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# testing a random forest classifier\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# fitting the data\n",
    "rfc.fit(X_train_ns, y_train_ns)\n",
    "\n",
    "# predicting\n",
    "rfc_preds = rfc.predict(X_test_ns)\n",
    "\n",
    "# checking model \n",
    "print(classification_report(y_test_ns, rfc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         4\n",
      "         2.0       0.00      0.00      0.00         4\n",
      "         3.0       0.52      0.48      0.50        23\n",
      "         4.0       0.31      0.38      0.34        21\n",
      "\n",
      "    accuracy                           0.37        52\n",
      "   macro avg       0.21      0.21      0.21        52\n",
      "weighted avg       0.36      0.37      0.36        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing a gradient boosting classifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# fitting the data\n",
    "gbc.fit(X_train_ns, y_train_ns)\n",
    "\n",
    "# predicting\n",
    "gbc_preds = gbc.predict(X_test_ns)\n",
    "\n",
    "# checking model \n",
    "print(classification_report(y_test_ns, gbc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         4\n",
      "         2.0       0.00      0.00      0.00         4\n",
      "         3.0       0.38      0.39      0.38        23\n",
      "         4.0       0.43      0.29      0.34        21\n",
      "\n",
      "    accuracy                           0.29        52\n",
      "   macro avg       0.20      0.17      0.18        52\n",
      "weighted avg       0.34      0.29      0.31        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing a gaussian naive bayes classifier\n",
    "gc = GaussianNB()\n",
    "\n",
    "# fitting the data\n",
    "gc.fit(X_train_ns, y_train_ns)\n",
    "\n",
    "# predicting\n",
    "gc_preds = gc.predict(X_test_ns)\n",
    "\n",
    "# checking model \n",
    "print(classification_report(y_test_ns, gc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.17      0.25      0.20         4\n",
      "         2.0       0.10      0.33      0.15         3\n",
      "         3.0       0.33      0.24      0.28        21\n",
      "         4.0       0.33      0.29      0.31        24\n",
      "\n",
      "    accuracy                           0.27        52\n",
      "   macro avg       0.23      0.28      0.24        52\n",
      "weighted avg       0.31      0.27      0.28        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing a KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# fitting the data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# predicting\n",
    "knn_preds = knn.predict(X_test)\n",
    "\n",
    "# checking model \n",
    "print(classification_report(y_test, knn_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.25      0.25      0.25         4\n",
      "         2.0       0.10      0.33      0.15         3\n",
      "         3.0       0.45      0.24      0.31        21\n",
      "         4.0       0.67      0.75      0.71        24\n",
      "\n",
      "    accuracy                           0.48        52\n",
      "   macro avg       0.37      0.39      0.36        52\n",
      "weighted avg       0.52      0.48      0.48        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing a KNN classifier with PCA reduced data\n",
    "knn1 = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# fitting the data\n",
    "knn1.fit(X_train_reduced, y_train)\n",
    "\n",
    "# predicting\n",
    "knn_preds1 = knn1.predict(X_test_reduced)\n",
    "\n",
    "# checking model \n",
    "print(classification_report(y_test, knn_preds1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         4\n",
      "         2.0       0.20      0.50      0.29         4\n",
      "         3.0       0.53      0.43      0.48        23\n",
      "         4.0       0.50      0.43      0.46        21\n",
      "\n",
      "    accuracy                           0.40        52\n",
      "   macro avg       0.31      0.34      0.31        52\n",
      "weighted avg       0.45      0.40      0.42        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing a random forest classifier on the reduced dataset\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# fitting the data\n",
    "rfc.fit(X_train_reduced_ns, y_train_ns)\n",
    "\n",
    "# predicting\n",
    "rfc_preds = rfc.predict(X_test_reduced_ns)\n",
    "\n",
    "# checking model \n",
    "print(classification_report(y_test_ns, rfc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         4\n",
      "         2.0       0.20      0.50      0.29         4\n",
      "         3.0       0.50      0.39      0.44        23\n",
      "         4.0       0.47      0.43      0.45        21\n",
      "\n",
      "    accuracy                           0.38        52\n",
      "   macro avg       0.29      0.33      0.29        52\n",
      "weighted avg       0.43      0.38      0.40        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing a gradient boosting classifier on the reduced data\n",
    "gbcr = GradientBoostingClassifier()\n",
    "\n",
    "# fitting the data\n",
    "gbcr.fit(X_train_reduced_ns, y_train_ns)\n",
    "\n",
    "# predicting\n",
    "gbc_predsr = gbcr.predict(X_test_reduced_ns)\n",
    "\n",
    "# checking model \n",
    "print(classification_report(y_test_ns, gbc_predsr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1152 candidates, totalling 3456 fits\n",
      "Best parameters are:  {'max_depth': 2, 'max_leaf_nodes': 16, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "# performing grid searches on the random forrest and gradient boosting classifier\n",
    "rfparams = {\n",
    "    'max_depth': [1,2,3,4,5,8,16,32],\n",
    "    'max_leaf_nodes': list(range(2, 20, 1)),\n",
    "    'min_samples_split': [2,3,4,5,8,12,16,20]\n",
    "}\n",
    "\n",
    "# initializing gridsearch\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(), rfparams, verbose=1, cv=3, n_jobs=-1)\n",
    "\n",
    "grid_search_rf.fit(X_train_ns, y_train_ns)\n",
    "\n",
    "# getting best params\n",
    "print(\"Best parameters are: \", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n",
      "Best parameters are:  {'max_depth': 14, 'max_leaf_nodes': 8, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "# performing another gridsearch for the random forest model\n",
    "rfparams = {\n",
    "    'max_depth': [12, 14, 16, 18, 20, 22, 24],\n",
    "    'max_leaf_nodes': [8],\n",
    "    'min_samples_split': [2,3]\n",
    "}\n",
    "\n",
    "# initializing gridsearch\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(), rfparams, verbose=1, cv=3, n_jobs=-1)\n",
    "\n",
    "grid_search_rf.fit(X_train_ns, y_train_ns)\n",
    "\n",
    "# getting best params\n",
    "print(\"Best parameters are: \", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best parameters are:  {'max_depth': 10, 'max_leaf_nodes': 8, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "# performing a final gridsearch for the random forest model\n",
    "rfparams = {\n",
    "    'max_depth': [10, 11, 12, 13],\n",
    "    'max_leaf_nodes': [8],\n",
    "    'min_samples_split': [2]\n",
    "}\n",
    "\n",
    "# initializing gridsearch\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(), rfparams, verbose=1, cv=3, n_jobs=-1)\n",
    "\n",
    "grid_search_rf.fit(X_train_ns, y_train_ns)\n",
    "\n",
    "# getting best params\n",
    "print(\"Best parameters are: \", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         4\n",
      "         2.0       0.00      0.00      0.00         4\n",
      "         3.0       0.55      0.52      0.53        23\n",
      "         4.0       0.43      0.62      0.51        21\n",
      "\n",
      "    accuracy                           0.48        52\n",
      "   macro avg       0.24      0.29      0.26        52\n",
      "weighted avg       0.42      0.48      0.44        52\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\billy\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\billy\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\billy\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# testing a random forest classifier with best parameters\n",
    "rfcbp = RandomForestClassifier(max_depth=12, max_leaf_nodes=8, min_samples_split=2)\n",
    "\n",
    "# fitting the data\n",
    "rfcbp.fit(X_train_ns, y_train_ns)\n",
    "\n",
    "# predicting\n",
    "rfc_preds = rfcbp.predict(X_test_ns)\n",
    "\n",
    "# checking model \n",
    "print(classification_report(y_test_ns, rfc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4608 candidates, totalling 13824 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\billy\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "3456 fits failed out of a total of 13824.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3456 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\billy\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\billy\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 577, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\billy\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 270, in _check_params\n",
      "    check_scalar(\n",
      "  File \"C:\\Users\\billy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1480, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: learning_rate == 0, must be > 0.0.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\billy\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.38562092 0.3711992  0.36139528]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are:  {'learning_rate': 0.1, 'max_depth': 3, 'max_leaf_nodes': 13, 'min_samples_split': 20}\n"
     ]
    }
   ],
   "source": [
    "# performing grid searches on the gradient boosting classifier DO NOT RERUN THIS CELL\n",
    "gbparams = {\n",
    "    'learning_rate': [0, .1, .5, 1],\n",
    "    'max_depth': [1,2,3,4,5,8,16,32],\n",
    "    'max_leaf_nodes': list(range(2, 20, 1)),\n",
    "    'min_samples_split': [2,3,4,5,8,12,16,20]\n",
    "}\n",
    "\n",
    "# initializing gridsearch\n",
    "grid_search_gc = GridSearchCV(GradientBoostingClassifier(), gbparams, verbose=1, cv=3, n_jobs=-1)\n",
    "\n",
    "grid_search_gc.fit(X_train_ns, y_train_ns)\n",
    "\n",
    "# getting best params\n",
    "print(\"Best parameters are: \", grid_search_gc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
      "Best parameters are:  {'learning_rate': 0.15, 'max_depth': 4, 'max_leaf_nodes': 13, 'min_samples_split': 20}\n"
     ]
    }
   ],
   "source": [
    "# performing grid searches on the gradient boosting classifier\n",
    "gbparams = {\n",
    "    'learning_rate': [.05, .1, .15, .22],\n",
    "    'max_depth': [2,3,4],\n",
    "    'max_leaf_nodes': [12,13,14],\n",
    "    'min_samples_split': [18,20,22,24]\n",
    "}\n",
    "\n",
    "# initializing gridsearch\n",
    "grid_search_gc = GridSearchCV(GradientBoostingClassifier(), gbparams, verbose=1, cv=3, n_jobs=-1)\n",
    "\n",
    "grid_search_gc.fit(X_train_ns, y_train_ns)\n",
    "\n",
    "# getting best params\n",
    "print(\"Best parameters are: \", grid_search_gc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         4\n",
      "         2.0       0.20      0.25      0.22         4\n",
      "         3.0       0.63      0.52      0.57        23\n",
      "         4.0       0.36      0.43      0.39        21\n",
      "\n",
      "    accuracy                           0.42        52\n",
      "   macro avg       0.30      0.30      0.30        52\n",
      "weighted avg       0.44      0.42      0.43        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing a gradient boosting classifier\n",
    "gbcgs = GradientBoostingClassifier(\n",
    "    learning_rate=.15, max_depth=4, max_leaf_nodes=13, min_samples_split=20\n",
    ")\n",
    "\n",
    "# fitting the data\n",
    "gbcgs.fit(X_train_ns, y_train_ns)\n",
    "\n",
    "# predicting\n",
    "gbcgs_preds = gbcgs.predict(X_test_ns)\n",
    "\n",
    "# checking model \n",
    "print(classification_report(y_test_ns, gbcgs_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the catboost model to .pkl since it was the best one\n",
    "qb_pickled_initial = pickle.dump(cat_model, open('qb_pickled_initial.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
